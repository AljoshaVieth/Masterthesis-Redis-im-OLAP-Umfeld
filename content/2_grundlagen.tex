% TODO: FIX LATEX ERRORS
\chapter{Technische Grundlagen}
\section{Beliebtheit von Technologien}
% Hier durch bessere Quelle austauschen
In der vorliegenden Arbeit wird die Popularität von bestimmten Technologien auf Basis zweier Indizes dargestellt: dem \emph{\acf{PYPL}}~\cite{carbonnelle_pypl_2023} sowie dem \emph{\acf{TOPDB}}~\cite{carbonnelle_topdb_2023}.  Diese Indizes dienen der Einschätzung der Beliebtheit von Programmiersprachen und Datenbanken und basieren hierbei auf der Häufigkeit von Google-Suchen.

Der \emph{\acf{PYPL}} misst die Beliebtheit von Programmiersprachen anhand der Analyse der Häufigkeit von Suchanfragen nach Tutorials auf Google. 
Dieser Index beruht auf der Annahme, dass eine höhere Anzahl von Suchanfragen nach Tutorials für eine bestimmte Sprache auf eine größere Beliebtheit dieser Sprache hinweist.

Der \emph{\acf{PYPL}} bewertet die Beliebtheit von Datenbanken anhand der Analyse der Suchhäufigkeit nach ihren Namen auf Google.  Eine erhöhte Suchfrequenz nach einer bestimmten Datenbank deutet dabei auf eine größere Popularität hin, ähnlich dem \emph{PYPL}-Index.

\section{\acf{OLAP}}
Viele Unternehmen verwenden heute große Mengen an Geschäftsdaten für eine strategische Planung.
Durch eine Analyse der Daten lassen sich Handlungsempfehlungen ableiten.
Typische Analysen umfassen die Berechnung des Umsatzes einer Filiale innerhalb des letzten Jahres sowie der Vergleich zu vorherigen Jahren oder die Analyse der Verkäufe von einzelnen Produkten in einem bestimmten Quartal.
Diese Analysen erfordern eine umfassende Datenmenge, einschließlich historischer Daten.
Klassische Datenbanksysteme für Transaktionen, etwa in einem Onlineshop, auch \acf{OLTP} genannt, sind für viele Schreib- und Lesezugriffe optimiert, nutzen meist wenig komplexe Abfragen (Queries) und enthalten häufig keine historischen Daten.
Datenbanken für analytische Zwecke sollten hingegen stark auf die Leseoperationen optimiert sein und müssen komplexere Queries in angemessener Zeit durchführen können.
Bei diesem Einsatzgebiet von Datenbanken spricht man vom \acf{OLAP}~\cite[S.~97f]{kleppmann_datenintensive_2019}.

\ac{OLAP} und \ac{OLTP} profitieren von verschiedenen Optimierungen der Datenstrukturen in einer Datenbank.
Bei Nutzung einer gemeinsamen Datenbank für beide Verfahren würden die \ac{OLAP}-Abfragen außerdem die \ac{OLTP}-Transaktionen verlangsamen oder blockieren.
Um das zu verhindern, nutzt man für \ac{OLAP} eigene Datenbanksysteme und speichert die Daten in sogenannten Data Warhouses.

\subsection{\acfp{DW}}
\acp{DW} wurden entwickelt, um Daten zu speichern, die für strategische Entscheidungen im Geschäftsumfeld nützlich sein können.
Dazu werden Daten aus Geschäftsprozessen wie etwa Verkäufen extrahiert, für die weitere Verwendung transformiert und in bestimmten Datenbanken gespeichert.
Klassische  operative oder transaktionale Datenbankansätze, die auf den täglichen Gebrauch durch viele Nutzende optimiert sind, eignen sich nicht für ein \ac{DW} im \ac{OLAP}-Umfeld, da hier üblicherweise keine historischen Daten gespeichert werden.
Des Weiteren enthalten diese detaillierte Daten, was das Ausführen von komplexen Abfragen erschwert bzw. verlangsamt.
% Hier ähnliche Inhalte wie im Kapitel weiter oben
Um aber Entscheidungen aus den Daten ableiten zu können, sind sowohl historische Daten als auch komplexe Abfragen notwendig.
Um diese Probleme zu lösen, enthält ein \ac{DW} im \ac{OLAP} Umfeld historische Daten und bietet ein optimiertes Datenmodell für komplexere Abfragen.
In der ursprünglichen Definition nach Inmon werden \acp{DW} als Sammlung von subjektorientierten, integrierten, nicht flüchtigen und zeitvariablen Daten beschrieben. % TODO: Hier wäre Originalquelle ganz praktisch
Subjektorientiert bedeutet, dass sich die Daten auf bestimmte Aspekte der geforderten Analyse beziehen, also z.~B. Daten über Produktionsmengen und Verkäufen bei Produktionsunternehmen.
Mit integrierten Daten ist gemeint, dass Daten aus verschiedenen Umgebungen in dem \ac{DW} integriert sind.
Nicht flüchtig bedeutet, dass die Daten über lange Zeiträume hinweg gespeichert bleiben und somit weder gelöscht noch modifiziert werden.
Zur Analyse ist es wichtig, Daten im zeitlichen Verlauf miteinander zu vergleichen, etwa um herauszufinden, wie sich die Verkäufe im letzten Quartal entwickelt haben.
Zeitvariabel beschriebt daher, dass Daten aus verschiedenen Zeitpunkten gespeichert werden~\cite[S.~3f]{vaisman_data_2022}.

\subsection{Datenstruktur in Data Warehouses im OLAP Umfeld}
Die Mehrheit der am häufigsten verwendeten Datenbanken nutzt ein relationales Datenbankmodell~\cite{db-engines_most_2023}. 
In einem solchen Modell können die Daten in verschiedenen Schemata aufgebaut sein.

\subsubsection{Normalisierung}
Eine gängige Praxis bei relationalen Datenbanken ist die Normalisierung.
Ziel der Normalisierung ist das Verhindern von redundanten Daten.
Enthalten mehrere Tabellen die gleichen Daten, so müssen diese Daten an mehreren Stellen bei Änderungen angepasst werden.
Um diesen Umstand zu verhindern, werden die Daten daher nur in einer Tabelle gespeichert und dann per Fremdschlüssel in den anderen Tabellen eingebunden~\cite[S.~24f]{vaisman_data_2022}.
Diese Fremdschlüssel benötigen in den meisten Fällen außerdem weniger Speicherplatz als die eigentlichen Daten, was einen weiteren Vorteil bietet.
Ein Nachteil der Normalisierung ist jedoch, dass Abfragen komplizierter werden und länger in der Ausführung benötigen, da die Daten aus verschiedenen Tabellen kombiniert werden müssen.

\subsubsection{Sternschema und Schneeflockenschema}
In \acp{DW}, die für große Datenmengen und komplexe Abfragen gedacht sind, bildet das Normalisieren durch die erschwerten Abfragen einen Nachteil.
Um Daten für Abfragen effizient zu speichern, werden diese nicht so weit wie möglich normalisiert, sondern anhand ihrer Inhalte verteilt. 
Durch Verständnis der Daten können diese in eine sogenannte Faktentabelle und viele Dimensionstabellen aufgeteilt werden.

In der Faktentabelle befinden sich die zentralen Metriken, die zur Analyse benötigt werden, etwa die Anzahl der Verkäufe eines Produktes.
Die Dimensionstabellen enthalten Daten, mit denen die Daten der Faktentabelle unter verschiedenen Umständen betrachtet werden können, etwa eine Dimensionstabelle mit Zeitpunkten oder Orten.
Diese Dimensionstabellen sind mit der Faktentabelle über Fremdschlüssel verbunden.

In einem Diagramm werden die Dimensionstabellen um die Faktentabelle angeordnet, wodurch das Diagramm einem Stern ähnelt, bei dem die Faktentabelle das Zentrum, und die Dimensionen die Strahlen bilden.
Deshalb spricht man auch von einem Sternschema.
Werden die Faktentabellen zusätzlich noch unterteilt, die Daten also noch normalisiert, spricht man von einem Schneeflockenschema.
Wie oben beschrieben eignen sich nicht normalisierte Daten jedoch besser für analytische Abfragen, weshalb das Sternschema oft bevorzugt wird.

Die Faktentabelle enthält den Großteil der Daten.
Jedes Ereignis wird in einer eigenen Zeile gespeichert, um somit so detailreich wie möglich analysieren zu können.
Des Weiteren kann die Faktentabelle sehr viele Spalten mit Details zu den Ereignissen enthalten.
Dimensionstabellen sind dahingegen wesentlich kleiner\cite[S.~101-103]{kleppmann_datenintensive_2019}.

Bei Abfragen können nun verschiedene Dimensionen kombiniert werden, um Daten aus der Faktentabelle abzufragen.
So können z.~B. die Verkäufe aus einem bestimmten Jahr in einer bestimmten Filiale aus der Faktentabelle abgefragt werden.
Die Dimensionstabellen können außerdem sogenannte Hierarchien enthalten, die verschiedene Genauigkeiten der Dimension definieren.
So kann ein Zeitpunkt in der Tabelle Werte für Uhrzeit, Tag, Monat, Quartal oder Jahr enthalten.
Ein Ort kann etwa aus dem Ortsnamen, dem Bundesland, dem Land, dem Kontinent bestehen.
So lassen sich genaue Abfragen zu Verkäufen einer bestimmten Filiale oder etwa allen Filialen in Europa abfragen~\cite[S.~5]{vaisman_data_2022}.

\subsection{OLAP Cubes}
In \emph{OLAP}-Systemen spielen Aggregatfunktionen wie \emph{COUNT}, \emph{SUM}, \emph{AVG}, \emph{MIN} und \emph{MAX} eine zentrale Rolle. Sie ermöglichen die effiziente Analyse und Aggregation großer Datenmengen. Eine Schlüsselstrategie zur Optimierung der Leistung von OLAP-Abfragen ist die Verwendung von \emph{materialisierten Aggregaten}. Diese entstehen, wenn häufig verwendete Aggregationsabfragen im Voraus berechnet und die Ergebnisse in einem Cache gespeichert werden.

Die Informationen in diesem Abschnitt beruhen auf der Beschreibung von Datenwürfeln durch Martin Kleppmann~\cite[S.~109-111]{kleppmann_datenintensive_2019}.

\emph{Materialisierte Sichten} sind in diesem Zusammenhang von besonderer Bedeutung. Sie dienen als Speicher für diese vorberechneten Daten. Strukturell ähneln sie den üblichen (virtuellen) Sichten (Views) in relationalen Datenbanksystemen und sind als tabellenähnliche Objekte konzipiert, die aggregierte Ergebnisse enthalten. Im Gegensatz zu virtuellen Sichten, die nur die Abfrage selbst speichern, enthalten materialisierte Sichten die tatsächlichen Abfrageergebnisse.

Ein zentrales Element in OLAP-Systemen ist der so genannte \emph{OLAP Cube} oder Datenwürfel, der eine spezialisierte Form der materialisierten Sicht darstellt. In einem OLAP-Würfel werden Daten als ein Gitter von Aggregaten dargestellt, die nach verschiedenen Dimensionen gruppiert sind. Ein solcher Würfel kann aus mehreren Dimensionen bestehen, wobei jede Seite des Würfels eine Dimension darstellt. Betrachtet man nur zwei Dimensionen, so kann man sich den OLAP-Würfel als eine zweidimensionale Tabelle vorstellen. In dieser Tabelle stellt beispielsweise eine Achse die Zeitdimension und die andere Achse die Produktdimension dar. Die Zellen der Tabelle enthalten dann das Aggregat (z.~B. \emph{MAX}) eines Attributs (z.~B. Verkaufspreis) für alle Fakten, die dieser Kombination von Dimensionen entsprechen. Der Cube ermöglicht es beispielsweise, den höchsten Verkaufspreis eines Produkts zu einem bestimmten Zeitpunkt abzurufen.

Ein weiterer Vorteil von Datenwürfeln ist die Möglichkeit, Aggregate unabhängig von einer bestimmten Dimension zu betrachten, wenn man sich entlang einer Achse des Würfels bewegt. So ist es beispielsweise möglich, den höchsten Verkaufspreis für jedes Produkt unabhängig vom Zeitpunkt oder den höchsten Preis zu bestimmten Zeitpunkten unabhängig vom Produkt zu ermitteln.

Trotz ihrer Effizienz bei der Beantwortung bestimmter Abfragen haben Datenwürfel auch Nachteile. Sie sind auf Abfragen beschränkt, für die die benötigten Daten bereits voraggregiert wurden. Dies führt zu einer eingeschränkten Flexibilität in Bezug auf die Art der Abfragen, die sie unterstützen können. Während sie sich also hervorragend für die schnelle Beantwortung bestimmter Abfragen eignen, ist ihre Anwendung begrenzt, wenn die erforderlichen Daten nicht bereits voraggregiert wurden.

%\begin{comment}
%\subsection{Der OLAP-Cube}
%%TODO: OLAP CUBE Voraggregation bei OLAP -> Kleppmann Seite 109 Kapitel 3
%
%
%% Tabelle überdenken
%\begin{table}[htbp] 
%    \centering
%    \footnotesize
%    \begin{tabular}{ccccc}
%        \toprule  
%        Id & Umsatz & Stückzahl & Zeit & Ort \\
%        \midrule
%        1 & 100,00 € & 50 & 1 & 1 \\
%        2 & 200,00 € & 100 & 2 & 2 \\
%        3 & 150,00 € & 75 & 3 & 3 \\
%        \bottomrule
%    \end{tabular}
%    \caption{Faktentabelle mit Umsatz, Stückzahl, Zeit und Ort}
%    \label{tab:faktentabelle}
%\end{table}
%
%\begin{table}[htbp] 
%    \centering
%    \footnotesize
%    \begin{tabular}{cccccc}
%        \toprule  
%        Id & Ortsname & Postleitzahl & Landkreis & Bundesland & Land \\
%        \midrule
%        1 & Furtwangen & 78120 & Schwarzwald-Baar-Kreis & Baden-Württemberg & Deutschland \\
%        2 & Schömberg & 75328 & Landkreis Calw & Baden-Württemberg & Deutschland \\
%        3 & Pforzheim & 75173 & Enzkreis & Baden-Württemberg & Deutschland \\
%        \bottomrule
%    \end{tabular}
%    \caption{Ortstabelle mit Ortsname, Postleitzahl, Landkreis, Bundesland und Land}
%    \label{tab:ortstabelle}
%\end{table}
%
%\begin{table}[htbp] 
%    \centering
%    \footnotesize
%    \begin{tabular}{cccccc}
%        \toprule  
%        Id & Timestamp & Datum & Monat & Quartal & Jahr \\
%        \midrule
%        1 & 02.12.1998 12:00 & 02.12.1998 & Dezember & 4 & 1998 \\
%        2 & 28.12.2007 12:00 & 02.01.2007 & Januar & 1 & 2007 \\
%        3 & 03.01.2023 16:00 & 03.01.2023 & Januar & 1 & 2023 \\
%        \bottomrule
%    \end{tabular}
%    \caption{Zeittabelle mit Timestamp, Datum, Monat, Quartal und Jahr}
%    \label{tab:zeittabelle}
%\end{table}
%
%
%% Eventuell Kapitel über Query Languages schreiben
%\subsection{Die \acs{SQL}-Sprache} % Titel verbessern
%% Code Listing ist auf englisch, zu deutsch ändern
%\begin{lstlisting}[
%    language=SQL,
%    caption=SQL Befehle zum Anlegen der Tabellen,
%    label=code:sql-creation-of-tables
%]
%CREATE TABLE Ortstabelle (
%    Id INT PRIMARY KEY,
%    Ortsname VARCHAR(255),
%    Postleitzahl CHAR(5),
%    Landkreis VARCHAR(255),
%    Bundesland VARCHAR(255),
%    Land VARCHAR(255)
%);
%
%CREATE TABLE Zeittabelle (
%    Id INT PRIMARY KEY,
%    Timestamp TIMESTAMP,
%    Datum DATE,
%    Monat VARCHAR(255),
%    Quartal SMALLINT,
%    Jahr SMALLINT
%);
%
%CREATE TABLE Faktentabelle (
%    Id INT PRIMARY KEY,
%    Umsatz VARCHAR(255),
%    Stueckzahl INT,
%    Zeit INT,
%    Ort INT,
%    FOREIGN KEY (Zeit) REFERENCES Zeittabelle(Id),
%    FOREIGN KEY (Ort) REFERENCES Ortstabelle(Id)
%);
%
%\end{lstlisting}
%
%In \cref{code:sql-creation-of-tables} werden \acs{SQL}-Befehle zum Erstellen der Beispieltabellen dargestellt.
%In den Befehlen werden die einzelnen Spalten der Tabelle mit ihren Datentypen angelegt.
%Verschiedene \acs{SQL}-Erweiterungen unterstützen verschiedene Datentypen, mit denen Daten teilweise effizienter gespeichert werden können.
%So bietet die \acs{SQL}-Erweiterung Transact-\acs{SQL} von Microsoft noch den Datentyp TINYINT der einen Wert von 0 bis 255 annehmen kann~\cite{ray_et_al_int_2023} und für die Spalte Quartal gut genutzt werden könnte.
%PostgreSQL bietet hingegen keinen solchen Datentypen~\cite{the_postgresql_global_development_group_81_2023} und da im Verlauf dieser Arbeit mit PostgreSQL gearbeitet wurde, wird auch in diesem Beispiel kein TINYINT verwendet.
%
%\end{comment}



\subsection{Key Value Stores in \acs{OLAP}} % wahrscheinlich hier nicht nötig

\section{Datenbank-Benchmarks}
Datenbank-Benchmarks geben einen Überblick über die Leistung von verschiedenen Datenbank\-systeme und die Hardware, auf der diese laufen.
%Datenbank-Benchmark oder Datenbankbenchmark ?
Die Non-Profit-Or\-ga\-ni\-sa\-tion \acf{TPC} hat verschiedene Datenbank-Benchmarks entwickelt, die bei der Wahl des Datenbank\-systems oder der Hardware helfen können~\cite[s. 619]{barata_overview_2015}.

\subsection{\acf{TPC-H}}
Der \acf{TPC-H} wurde zum Testen von analytischen Datenbanken entwickelt.
Die Daten und Abfragen des Benchmarks sind auf eine Datenbank ausgelegt, mit der ein Anbieter seine Geschäftsdaten analysieren kann~\cite[S.~624-626]{barata_overview_2015}

\subsection{\acf{SSB}}
Der \acf{SSB} ist eine abgewandelte Form des \ac{TPC-H}.

\subsubsection{Schema des \ac{SSB}}
Er verwendet die gleichen Daten, nutzt dafür jedoch ein Sternschema statt eines normalisierten Schemas.
Um die Daten an ein Sternschema anzupassen, wurden die normalisierte Struktur des \ac{TPC-H} denormalisiert.
Somit wurden einige Tabellen zusammengelegt.
Außerdem wurden einige, für OLAP unwichtige, Daten entfernt.
Im Paper~\cite{oneil_star_2009} zum \ac{SSB} werden die Änderungen im Detail beschrieben.
% Hier habe ich mich bewusst dazu entschieden, nicht darauf einzugehen, welche Tabellen aus TPC-H wie verändert wurden, da TPC-H irrelevant für diese Arbeit ist.
Nach den Anpassungen sind die Daten in einer Faktentabelle namens LINEORDER sowie den Dimensionstabellen CUSTOMER, PART, SUPPLIER und DATE organisiert (siehe Abbildung~\ref{pic:ssb-schema}).
Die Felder innerhalb der Tabellen beginnen mit einem Präfix, bestehend aus dem Anfangsbuchstaben der Tabelle und einem Unterstrich, also etwa d\_year in der DATE-Tabelle.

\begin{figure}[ht]  % figure position
    \centering      % center the image
    \includegraphics[width=1\textwidth]{pictures/ssb/ssb-schema.png}
    \caption{Schema des \ac{SSB} aus dem originalen Paper~\cite{oneil_star_2009}}      % caption the image
    \label{pic:ssb-schema}    % label the image for internal referencing
\end{figure}


\subsubsection{Queries des \ac{SSB}}
Die Queries des \ac{SSB} unterscheiden sich von denen des \ac{TPC-H}.
Der \ac{SSB} nutzt nur Queries, die genau eine SELECT-Anweisung auf der Faktentabelle LINEORDER nutzen und somit keine self-joins nutzen. %self-joins bissl weirder Ausdruck
Die LINEORDER Tabelle wird dann mit einer oder mehreren Dimensionstabellen gejoint und die Ergebnisse somit gefiltert. 
%TODO: Alle SSB SQL-Queries in den Anhang packen

Die Queries des \ac{SSB} sind in vier Kategorien aufgeteilt (query flights): % query flights bissl weird

%TODO: \usepackage{underscore}

\paragraph{Q1}
%ausbauen
Queries in Q1 schränken die Daten über nur eine Dimension, \emph{DATE}, ein.
Die Faktentabelle \emph{LINEORDER} wird mit der Dimensionstabelle\emph{DATE} gejoint und die Daten anhand einer Zeitspanne aus der DATE-Tabelle und den Bereichen der Felder \emph{lo\_discount} und \emph{lo\_quantity} aus der LINEORDER-Tabelle gefiltert.
Anschließend wird der Umsatz als Summe der Produkte der Felder \emph{lo\_extendedprice} und \emph{lo\_discount} berechnet und als \emph{revenue} zurückgegeben \cite{oneil_star_2009}.


\begin{lstlisting}[
    language=SQL,
    caption=SQL Query-Struktur für Q1 des \ac{SSB},
    label=code:ssb-q1-structur-example
]
SELECT 
    SUM(lo_extendedprice * lo_discount) AS revenue
FROM 
    lineorder, date
WHERE 
    lo_orderdate = d_datekey
    AND d_year = [YEAR]
    -- Specific values below
    AND lo_discount BETWEEN [DISCOUNT] - 1 AND [DISCOUNT] + 1
    AND lo_quantity < [QUANTITY];
\end{lstlisting}

\paragraph{Q2}
In Q2 schränken die Queries die Daten über zwei Dimensionen ein: \emph{PART} und \emph{SUPPLIER}.
Anschließend wird wie in Q1 der Umsatz gebildet, wobei die Ergebnisse hier noch nach \emph{d\_year} und \emph{p\_brand1} gruppiert und sortiert werden.  
In Q2 werden insgesamt vier Tabellen (\emph{LINEORDER}, \emph{PART}, \emph{SUPPLIER}, \emph{DATE}) gejoint.
\begin{lstlisting}[
    language=SQL,
    caption=SQL Query-Struktur für Q2 des \ac{SSB},
    label=code:ssb-q2-structur-example
]
SELECT 
    SUM(lo_revenue) AS total_revenue, d_year, p_brand1
FROM 
    lineorder, date, part, supplier
WHERE 
    lo_orderdate = d_datekey
    AND lo_partkey = p_partkey
    AND lo_suppkey = s_suppkey
    AND p_category = 'MFGR#12'
    AND s_region = 'AMERICA'
GROUP BY 
    d_year, p_brand1
ORDER BY 
    d_year, p_brand1;

\end{lstlisting}

\paragraph{Q3}
In Q3 schränken die Queries die Daten über drei Dimensionen ein: \emph{DATE}, \emph{SUPPLIER} und \emph{CUSTOMER}.
Wie in Q1 und Q2 werden auch hier die Umsätze gebildet.
Anschließend werden sie nach \emph{c\_nation}, \emph{s\_region} und \emph{d\_year} gruppiert und nach \emph{d\_year} sortiert.
Es werden insgesamt vier Tabellen (\emph{LINEORDER}, \emph{DATE}, \emph{SUPPLIER} und \emph{CUSTOMER}) gejoint.
\begin{lstlisting}[
    language=SQL,
    caption=SQL Query-Struktur für Q3 des \ac{SSB},
    label=code:ssb-q3-structur-example
]
SELECT 
    c_nation, s_nation, d_year, SUM(lo_revenue) AS revenue
FROM 
    customer, lineorder, supplier, date
WHERE 
    lo_custkey = c_custkey
    AND lo_suppkey = s_suppkey
    AND lo_orderdate = d_datekey
    AND c_region = 'ASIA'
    AND s_region = 'ASIA'
    AND d_year >= 1992
    AND d_year <= 1997
GROUP BY 
    c_nation, s_nation, d_year
ORDER BY 
    d_year ASC, revenue DESC;
\end{lstlisting}

\paragraph{Q4}
Die Queries von Q4 schränken die Daten basierend auf drei Dimensionen\\ (\emph{CUSTOMER}, \emph{SUPPLIER} und \emph{PART}) ein.
Auch hier wird wieder der Umsatz berechnet.
Dieses Mal wird er durch \emph{d\_year} und \emph{c\_nation} gruppiert und sortiert.
Hier werden erstmals alle fünf Tabellen (\emph{LINEORDER}, \emph{CUSTOMER}, \emph{SUPPLIER}, \emph{PART} und \emph{DATE}) gejoint.

\begin{lstlisting}[
    language=SQL,
    caption=SQL Query-Struktur für Q4 des \ac{SSB},
    label=code:ssb-q4-structur-example
]
SELECT 
    d_year, c_nation, SUM(lo_revenue - lo_supplycost) AS profit
FROM 
    date, customer, supplier, part, lineorder
WHERE 
    lo_custkey = c_custkey
    AND lo_suppkey = s_suppkey
    AND lo_partkey = p_partkey
    AND lo_orderdate = d_datekey
    AND c_region = 'AMERICA'
    AND s_region = 'AMERICA'
    AND (p_mfgr = 'MFGR#1' OR p_mfgr = 'MFGR#2')
GROUP BY 
    d_year, c_nation
ORDER BY 
    d_year, c_nation;

\end{lstlisting}

\section{PostgreSQL}
\emph{PostgreSQL} ist ein relationales Datenbankmanagementsystem, welches die \emph{SQL}-Spra\-che ver\-wen\-det und erweitert. Die folgenden Informationen basieren auf der offiziellen Webseite von \emph{PostgreSQL}~\cite{the_postgresql_global_development_group_postgresql_nodate}. Es handelt sich dabei um ein Open-Source-Projekt, welches seit über 35 Jahren entwickelt wird. Im Jahr 2023 belegt \emph{PostgreSQL} gemäß dem \emph{DB-Engines Ranking}~\cite{db-engines_most_2023} weltweit den vierten Platz unter den beliebtesten Datenbankmanagementsystemen, nach \emph{Oracle}, \emph{MySQL} und dem \emph{Microsoft SQL Server}.

\emph{PostgreSQL} zeichnet sich durch eine bewährte Architektur, Zuverlässigkeit, Datenintegrität, einen robusten Funktionsumfang und Erweiterbarkeit aus. Das System ist auf allen wichtigen Betriebssystemen lauffähig und seit 2001 \emph{ACID}-konform.  Zusätzlich verfügt es über leistungsstarke Zusatzmodule wie zum Beispiel \emph{PostGIS}, ein beliebtes erweiterbares Geodatenbank-System.

Die Erweiterbarkeit von \emph{PostgreSQL} ist ein weiteres Schlüsselfeature. Benutzer können eigene Datentypen definieren, benutzerdefinierte Funktionen erstellen und Code aus verschiedenen Programmiersprachen integrieren, ohne die Datenbank neu kompilieren zu müssen.

\emph{PostgreSQL} strebt danach, dem SQL-Standard zu entsprechen, solange diese Konformität nicht traditionellen Funktionen widerspricht oder zu schlechten Architekturentscheidungen führen würde. Viele der vom SQL-Standard geforderten Funktionen werden unterstützt, auch wenn teilweise mit leicht abweichender Syntax oder Funktion.

Ein weiterer wichtiger Aspekt von \emph{PostgreSQL} ist seine Skalierbarkeit. Es hat sich gezeigt, dass das System sowohl in Bezug auf die Menge der zu verwaltenden Daten als auch auf die Anzahl gleichzeitig aktiver Benutzer sehr skalierbar ist. In Produktionsumgebungen gibt es aktive \emph{PostgreSQL}-Cluster, die mehrere Terabyte an Daten verwalten, sowie spezialisierte Systeme, die Petabyte an Daten bewältigen.

% WARUM POSTGRESQL statt SQL oder so?
In der vorliegenden Arbeit wird \emph{PostgreSQL} als Vergleichsbasis zu \emph{Redis} im Kontext des \ac{SSB} verwendet. Es ist hervorzuheben, dass der primäre Fokus dieser Arbeit auf der Untersuchung und Analyse von \emph{Redis} liegt. Daher wird \emph{PostgreSQL} als Referenzsystem für Vergleichszwecke verwendet, jedoch nicht in gleichem Maße wie \emph{Redis} behandelt.

\section{Redis}

Redis ist ein Key-Value Store, der vollständig im Arbeitsspeicher (in-memory) arbeitet und heute häufig als Datenbank, Cache, Message Broker oder Streaming Engine eingesetzt wird~\cite{redis_ltd_introduction_nodate}.
In Redis können unterschiedliche Datenstrukturen verwendet werden. Dazu gehören Strings, Hashes, Listen, Sets, sortierte Sets, Bitmaps, Bitfields, georäumliche Indizes, Streams sowie HyperLogLog~\cite{redis_ltd_data_nodate}.
Mit Erweiterungen, so genannten Modulen, können weitere Datentypen wie z.~B. JSON oder Time series unterstützt werden.
Redis wird von vielen bekannten Unternehmen wie GitHub, StackOverflow, Snapchat, Craigslist oder X verwendet~\cite{redis_ltd_whos_nodate}.
Redis wird immer kostengünstiger einsetzbar, da die Arbeitsspeicher im Preis immer weiter fallen~\cite{bergai_trends_2020}.

Des weiteren besteht mit \enquote{Auto Tiering} die Möglichkeit, Arbeitsspeicher zusammen mit SSD-Speicher zu nutzen was die Infrastrukturkosten um bis zu 70\% senken kann~\cite{redis_ltd_auto_nodate}. Dieses Feature ist jedoch nur mit \enquote{Redis Enterprise} möglich.


% Hier ist was doppelt, muss überprüft werden (wahrscheinlich untere lassen, obere entfernen)
% Besseren Einleitungssatz mit Quelle

Redis ist eine vielseitige Datenbank, die sich nicht streng als herkömmliche Datenbank kategorisieren lässt. Obwohl Redis die grundlegenden Anforderungen an eine traditionelle Datenbank erfüllt, wie das Sammeln und Speichern von Informationen, die dann leicht abgerufen, bearbeitet oder gelöscht werden können, bietet Redis zusätzliche Funktionen, die vor allem durch die Geschwindigkeit aufgrund der vollständigen Ausführung im Arbeitsspeicher und die vielseitigen Datenstrukturen ermöglicht werden.
Durch die Persistierung der Daten auf der Festplatte kann Redis als konventionelle Datenbank genutzt werden.

Außerdem kann Redis als Cache und Message Broker dienen.

Die hohe Geschwindigkeit von Redis erlaubt eine vorteilhafte Verbindung mit anderen Datenbanken, wodurch Redis als optimale Wahl für den Cache von anderen, oft langsameren Datenbanken gilt. So kann Redis beispielsweise genutzt werden um in Echtzeit mit Nutzern zu interagieren währen die Historie der Transaktionen in einer anderen Datenbank gespeichert wird.

Redis bietet als Message-Broker dank des Publish-Subscribe-Paradigmas eine Lösung, um publizierte Nachrichten effizient über bestimmte Kanäle an Abonnenten zu verteilen. Hierbei hat Redis durch seine vielseitigen Datenstrukturen oft Vorteile gegenüber anderen etablierten Message-Brokern~\cite{joshi_you_nodate}.

\subsection{Module für Redis}
\subsubsection{Redis Stack}
\emph{Redis Stack} erweitert das klassische \emph{Redis} mit Modulen.
Die Informationen, die diesem Abschnitt zugrunde liegen, stammen von der offiziellen Webseite von Redis~\cite{redis_ltd_about_nodate}.
\emph{Redis Stack} kombiniert Redis mit den Modulen \emph{RediSearch}, \emph{RedisJSON}, \emph{RedisTimeSeries} und \emph{RedisBloom} zu einem benutzerfreundlichen Paket.
Dieses Paket ermöglicht erweiterte Funktionen wie die Verwendung probabilistischer Datenstrukturen, Abfragen von JSON-Dokumenten, kombinierte Abfragen von Hashes und JSON-Dokumenten sowie die Verarbeitung und Abfrage von Zeitreihendaten einschließlich Volltextsuche.

Ziel von \emph{Redis Stack} ist es, die Entwicklung von Echtzeitanwendungen zu erleichtern, indem eine Backend-Datenplattform bereitgestellt wird, die Anfragen zuverlässig in Millisekunden oder weniger verarbeiten kann.

Für die vorliegende Arbeit wurde nur das Modul \emph{RediSearch} verwendet, in der Dokumentation werden die Technologien von \emph{Redis Stack} jedoch oft gemeinsam beschrieben. 
Außerdem wurde das offizielle \emph{Docker-Image} des \emph{Redis Stack}~\cite{redis_ltd_run_nodate} verwendet, da dies der einfachste Weg ist, Redis mit \emph{RediSearch} zu betreiben. 

\emph{RediSearch} wird im weiteren Verlauf dieser Arbeit ausführlich beschrieben.

\subsection{Datentypen in Redis}
\subsubsection{Strings}
Strings in Redis sind grundlegende Datentypen, die eine Folge von Bytes repräsentieren.
Sie können verschiedene Inhalte wie Text, serialisierte Objekte oder binäre Datenarrays repräsentieren und sind auf eine maximale Größe von 512 MB beschränkt.
Diese Strings unterstützen bitweise Operationen und Funktionen wie Zähler, die durch atomare Inkremente und Dekremente gegen Race-Conditions bei gleichzeitigem Zugriff mehrerer Clients geschützt sind.

Die primären Befehle für die Arbeit mit Strings sind \emph{SET} und \emph{GET}, die das Setzen und Abrufen von Werten ermöglichen, während \emph{MSET} und \emph{MGET} das gleichzeitige Setzen oder Abrufen mehrerer Werte erlauben.

Obwohl die meisten String-Operationen eine konstante Ausführungszeit von O(1) haben und somit sehr effizient sind, benötigen einige Operationen wie \emph{SUBSTR}, \emph{GETRANGE} oder \emph{SETRANGE} eine Ausführungszeit von O(n)~\cite{redis_ltd_strings_nodate}.

\subsubsection{Hashes}
Hashes in Redis dienen als essenzielle Strukturen für die Speicherung von Key-Value-Paaren und ähneln in ihrer Funktionsweise den HashMaps in Java oder Dictionaries in Python. Sie eignen sich insbesondere für die Darstellung grundlegender Objekte und das Speichern von Zählergruppierungen. Ein Hash in Redis kann bis zu \(2^{32} - 1\) Felder enthalten, was eine umfangreiche Kapazität für die Datenorganisation bietet.

In Hashes können beispielsweise Daten von Nutzern einer Applikation wie Vorname, Nachname, Emailadresse gespeichert werden.
Hashes können auch genutzt werden um Daten aus relationalen Datenbanken in Redis darzustellen indem die Spalten als Keys genutzt werden. Jeder Hash stellt so eine Zeile aus einer relationalen Datenbank dar.

Für die Arbeit mit Hashes stellt Redis verschiedene Befehle bereit. Der Befehl \emph{HSET} ermöglicht das Setzen mehrerer Felder eines Hashes, wohingegen \emph{HGET} für das Abrufen des Wertes eines einzelnen Feldes genutzt wird. \emph{HMGET} bietet eine ähnliche Funktion wie \emph{HGET}, gibt jedoch die Werte mehrerer Felder in Form eines Arrays zurück.

Bei der Betrachtung der Performance von Hash-Befehlen in Redis zeichnen sich die meisten durch eine Effizienz mit einer Komplexität von O(1) aus. Allerdings gibt es auch Befehle wie \emph{HKEYS}, \emph{HVALS} und \emph{HGETALL}, deren Komplexität O(n) beträgt, wobei n für die Anzahl der Feld-Wert-Paare im Hash steht. Diese Differenzierung in der Performance ist bei der Anwendung von Hashes in Redis entscheidend, um eine optimale Effizienz und Leistung zu gewährleisten.

~\cite{redis_ltd_hashes_nodate}.
\subsubsection{Listen}
Der Listen-Datentyp in Redis besteht aus verketteten Listen von String-Werten. Er wird häufig verwendet, um Stacks und Queues zu implementieren sowie Queue-Management-Systeme für Hintergrundprozesse zu bauen.
Die maximale Länge einer Redis-Liste beträgt \(2^{32} - 1\) (4.294.967.295) Elemente.

Die grundlegenden Befehle zum Manipulieren von Listen sind \emph{LPUSH} und \emph{RPUSH}, um Elemente am Anfang oder Ende der Liste hinzuzufügen, \emph{LPOP} und \emph{RPOP}, um Elemente von den entsprechenden Enden zu entfernen, und \emph{LLEN}, um die Länge der Liste zu ermitteln.
\emph{LMOVE} und \emph{LTRIM} erlauben das Verschieben von Elementen zwischen Listen oder das Begrenzen von Listen auf eine bestimmte Anzahl von Elementen.

In Redis unterstützen Listen blockierende Befehle wie \emph{BLPOP} und \emph{BLMOVE}, die warten, bis Elemente verfügbar sind, bevor sie Operationen ausführen.
Dies ist besonders nützlich für die Implementierung von Warteschlangen und Prozesskommunikation. So müssen Clients nicht durchgängig neue Anfragen senden falls keine neuen Daten verfügbar sind.
Bibliotheken wie \emph{Resque} und \emph{Sidekiq} nutzen diese Funktionen zur Verwaltung von Hintergrundjobs in Ruby.
Twitter nutzt Redis-Listen zur Speicherung der neuesten Tweets.

Redis-Listen sind effizient beim Hinzufügen sowie Entfernen von Elementen an beiden Enden, da diese Operationen unabhängig von der Listenlänge in konstanter Zeit (O(1)) ausgeführt werden.
Damit eignen sie sich ideal für Echtzeitanwendungen, die schnelle Aktualisierungen erfordern. 
Operationen wie \emph{LINDEX}, die einen Zugriff auf ein Element mitten in der Liste erfordern, sind langsamer, da die benötigte Zeit mit der Position des Elements in der Liste skaliert (O(n)).
Redis-Listen bieten jedoch die Möglichkeit, sie als begrenzte Sammlungen für Anwendungen zu verwenden, bei denen nur die letzten N Einträge von Interesse sind.
In diesem Fall wird die Operation \emph{LTRIM} verwendet, um die Liste auf eine feste Anzahl von Elementen zu beschränken.


Redis erstellt und entfernt Schlüssel automatisch beim Erstellen oder Leeren von Listen~\cite{redis_ltd_lists_nodate}.


\subsubsection{Sets}
Sets in Redis sind eine Datenstruktur für ungeordnete Sammlungen einzigartiger Strings.
Sie eignen sich daher gut für Aufgaben wie das Speichern aller verschiedenen Besucher-IDs einer Webseite oder das Erfassen aller Mitarbeiter einer bestimmten Unternehmensabteilung.
Des Weiteren erlauben Sets die Ausführung gängiger Mengenoperationen wie Schnittmengen, Vereinigungen und Differenzen.
Ein Set kann bis zu \(2^{32} - 1\) Elemente enthalten, was 4.294.967.295 Elementen entspricht.

Die Kernbefehle für die Arbeit mit Sets umfassen \emph{SADD}, um ein neues Element hinzuzufügen, \emph{SREM}, um ein bestimmtes Element zu entfernen, \emph{SISMEMBER}, um die Zugehörigkeit eines Strings zu testen, \emph{SINTER}, um die Schnittmenge von zwei oder mehr Sets zu ermitteln, und \emph{SCARD}, um die Größe eines Sets zu bestimmen.
Zum Entfernen von Elementen aus einem Set kann der Befehl \emph{SREM} verwendet werden, um ein oder mehrere Elemente zu entfernen, oder der Befehl \emph{SPOP}, um ein zufälliges Element zu entfernen.
Der Befehl \emph{SRANDMEMBER} gibt ein zufälliges Element zurück, ohne es zu entfernen.

Neben trivialen gibt es auch komplexe Operationen, die mit den geeigneten Redis-Befehlen einfach zu implementieren sind.
Eine Buchhandlung kann zum Beispiel den \emph{SINTER}-Befehl in Redis verwenden, um Kunden herauszufinden, die in verschiedenen Ländern wie Deutschland und Frankreich ein gemeinsames Interesse an einem Genre, zum Beispiel Science-Fiction, haben.
Zusätzlich zur Schnittmenge können auch Vereinigungs- und Differenzmengen gebildet werden.

Die meisten Operationen wie das Hinzufügen, Entfernen oder Überprüfen der Zugehörigkeit eines Elements zu einem Set sind mit einer Laufzeit von O(1) sehr effizient.
Der Befehl \emph{SMEMBERS} hingegen ist mit O(n) zu bewerten und kann insbesondere bei großen Sets zu langen Ausführungszeiten führen, da er das gesamte Set zurückgibt.
Als Alternative bietet sich der Befehl \emph{SSCAN} an, der ein iteratives Abfragen der Set-Inhalte ermöglicht.

Sets werden oft als Index verwendet. Für eine effiziente Verwaltung von Indizes innerhalb von Redis empfiehlt sich aber das \emph{RediSearch}-Modul~\cite{redis_ltd_sets_nodate}.


\subsubsection{Sortierte Sets (Sorted Sets)}
% \emph Nutzung überprüfen
Ein \emph{Sorted Set} in Redis repräsentiert eine Menge an einzigartigen Strings, die basierend auf einer zugehörigen \emph{Score}-Wertung geordnet sind. Diese Datenstruktur eignet sich besonders für Anwendungsfälle wie Ranglisten oder die Implementierung eines \emph{Rate Limiters} mittels eines gleitenden Zeitfensters (\emph{sliding-window}). Der wesentliche Vorteil eines \emph{Sorted Sets} gegenüber einem herkömmlichen Set liegt in der sofortigen Sortierung der Elemente bei der Einfügung und nicht erst bei der Abfrage. % Limiter überprüfen

Jeder \emph{Score} ist als Gleitkommazahl definiert, wobei die Sortierung primär nach dem \emph{Score} erfolgt. Bei identischen \emph{Scores} bestimmt die lexikographische Reihenfolge der Strings die Positionierung der Elemente. Die Einzigartigkeit der Strings garantiert dabei eine klare Ordnung innerhalb des Sets. Es ist möglich, die \emph{Scores} nachträglich zu aktualisieren, und bei erneutem Einfügen eines Elements wird sowohl der \emph{Score} als auch die Position angepasst, mit einem Rechenaufwand von \(O(\log(N))\), wobei \(N\) die Anzahl der Elemente im Set ist.

Die grundlegenden Befehle für die Arbeit mit \emph{Sorted Sets} sind \emph{ZADD} zum Hinzufügen oder Aktualisieren des \emph{Scores} von Elementen, \emph{ZREM} zum Entfernen von Elementen, \emph{ZRANGE} zum Zurückgeben von Mitgliedern in einem bestimmten Bereich (optional mit \emph{Scores} über `WITHSCORES`), \emph{ZRANGEBYSCORE} zum Abrufen von Elementen in einem bestimmten \emph{Score}-Bereich, und \emph{ZRANK} bzw. \emph{ZREVRANK} zur Ermittlung des Rangs eines Elements in aufsteigender oder absteigender Sortierreihenfolge.

Für lexikographische Bereiche stehen Befehle wie \emph{ZRANGEBYLEX}, \emph{ZREVRANGEBYLEX}, \emph{ZREMRANGEBYLEX} und \emph{ZLEXCOUNT} zur Verfügung.

Die meisten Operationen auf \emph{Sorted Sets} haben eine Laufzeit von \(O(\log(n))\), mit Ausnahme von \emph{ZRANGE}, dessen Laufzeit \(O(\log(n) + m)\) beträgt, wobei \(m\) die Anzahl der zurückzugebenden Elemente ist.

Technisch gesehen sind \emph{Sorted Sets} durch eine duale Datenstruktur realisiert, die eine Skip-List und eine Hash-Tabelle kombiniert, sodass jede Einfügung eine \(O(\log(N))\) Operation darstellt. Die vorsortierte Natur der \emph{Sorted Sets} ermöglicht einen effizienten Zugriff ohne zusätzlichen Sortieraufwand bei der Abfrage.

Obwohl \emph{Sorted Sets} auch für die Indizierung verwendet werden können, ist für den Aufbau eines effizienten Index in Redis das Modul RediSearch zu empfehlen~\cite{redis_ltd_sorted-sets_nodate}.


\subsubsection{Streams}
Redis Streams sind eine Datenstruktur in Redis, die als anhängbares Protokoll (ap\-pend-on\-ly log) fungiert und gleichzeitig mehrere Operationen zur Überwindung der Grenzen typischer anhängbarer Protokolle implementiert. Diese umfassen unter anderem den wahlfreien Zugriff (\enquote{random access}) in O(1)-Zeit und komplexe Konsumstrategien wie Verbrauchergruppen.
Die Anwendungsbereiche von Redis Streams sind vielfältig und schließen Event Sourcing, Sensorüberwachung und Benachrichtigungssysteme ein.

Falls nicht anders vorgegeben generiert Redis für jeden Eintrag in einem Stream automatisch eine eindeutige ID, die auch Zeitinformationen beinhaltet, was den effizienten Abruf und Bereichsabfragen ermöglicht.

Grundlegende Befehle zur Interaktion mit Redis Streams sind \emph{XADD} für das Hinzufügen, \emph{XREAD} für das Lesen, \emph{XRANGE} für Bereichsabfragen und \emph{XLEN} zur Bestimmung der Länge eines Streams.

Consumer Groups in Redis sorgen für eine effiziente Verteilung von Nachrichten, indem sie sicherstellen, dass jede Nachricht nur einmal an einen Konsumenten geliefert wird. Dies ermöglicht auch die Nachverfolgung von noch nicht bestätigten Nachrichten. Zur Überwachung und Verwaltung dieser Streams und Consumer Groups dienen Befehle wie \emph{XPENDING} und \emph{XINFO}.

Die Begrenzung der Datenspeicherung in Redis Streams wird durch den \emph{MAXLEN}-Parameter im \emph{XADD}-Befehl realisiert.

Wie andere Redis-Datenstrukturen werden Streams asynchron auf Repliken repliziert und in AOF- sowie RDB-Dateien persistiert, einschließlich der Zustände von Consumer Groups.

Das Hinzufügen eines Eintrags zu einem Redis Stream ist eine O(1)-Operation, während der Zugriff auf einzelne Einträge als O(n)-Operation charakterisiert wird, wobei n die Länge der ID darstellt. In der Regel sind diese IDs kurz, was zu einem relativ konstanten Zeitaufwand führt, allerdings kann dieser Aufwand variieren, je nach spezifischer Anwendung und Struktur der IDs~\cite{redis_ltd_streams_nodate}.

\subsubsection{Bitmaps}
Bitmaps sind in Redis kein eigener Datentyp sondern eine Reihe an bit-orientierten Operationen auf dem String-Datentyp der wie ein Bit-Vektor genutzt wird. Da Strings in Redis binärsicher sind und eine maximale Länge von 512 MB aufweisen, eignen sie sich gut, um bis zu \(2^{32}\) unterschiedliche Bits zu setzen.
Bitweise Operationen lassen sich sowohl auf einzelne als auch auf mehrere dieser Strings anwenden.

Bitmaps können so für eine effiziente Darstellung von Sets, bei denen die Mitglieder des Sets den ganzen Zahlen von 0 bis N entsprechen, genutzt werden.

Ein praktisches Anwendungsbeispiel für Bitmaps in Redis ist ein Park\-haus-Ver\-wal\-tungs\-system, in dem jeder Parkplatz durch ein Bit repräsentiert wird. Hierbei werden belegte Parkplätze durch ein Bit im Wert 1 und freie Parkplätze durch ein Bit im Wert 0 dargestellt.

Redis bietet einige grundlegende Befehle zur Arbeit mit Bitmaps. Der Befehl \emph{SETBIT} dient dazu, ein Bit an einem bestimmten Offset auf 0 oder 1 zu setzen, während \emph{GETBIT} den Wert eines Bits an einem gegebenen Offset zurückgibt. Mit \emph{BITOP} lassen sich bitweise Operationen an einem oder mehreren Strings durchführen. \emph{BITCOUNT} führt eine Populationszählung durch und berichtet die Anzahl der auf 1 gesetzten Bits. \emph{BITPOS} schließlich findet das erste Bit mit dem spezifizierten Wert von 0 oder 1.

% TODO: Was ist denn konstantzeitigen
Es gibt zwei Kategorien von Bitoperationen: die konstantzeitigen Ein\-zel\-bit-O\-pe\-ra\-ti\-o\-nen, wie das Setzen oder Abrufen eines Bitwertes, und Operationen auf Bitgruppen, wie das Zählen der Anzahl gesetzter Bits in einem bestimmten Bereich. Diese zweite Kategorie umfasst beispielsweise die Populationszählung.

Bitmaps bieten den großen Vorteil, dass sie häufig erhebliche Speicherplatzersparnisse bei der Speicherung von Informationen ermöglichen.Zum Beispiel kann in einem System, das Benutzer über fortlaufende IDs identifiziert, ein Bit pro Benutzer genutzt werden, um eine einfache Information wie den Wunsch, einen Newsletter zu erhalten, zu speichern. Mit dieser Methode lassen sich solche Daten für bis zu 4 Milliarden Benutzer mit nur 512 MB Speicher verwalten.

Die Performance von Bitmap-Befehlen in Redis variiert je nach Art der Operation. Die Befehle \emph{SETBIT} und \emph{GETBIT} werden in konstanter Zeit, also in O(1), ausgeführt. Der Befehl \emph{BITOP} hat hingegen eine Ausführungszeit von O(n), wobei n die Länge des längsten Strings in der Vergleichsoperation darstellt~\cite{redis_ltd_bitmaps_nodate}.


\subsubsection{Bitfields}
Wie Bitmaps, so werden auch Bitfelder (\emph{\enquote{Bitfields}}) in Redis in Zeichenketten gespeichert. Diese sind jedoch binär kodiert. Bitfelder in Redis ermöglichen es, Ganzzahlen beliebiger Bitlänge zu setzen, zu inkrementieren und abzufragen. Man kann beispielsweise mit Ganzzahlen arbeiten, die von vorzeichenlosen 1-Bit-Integers bis zu vorzeichenbehafteten 63-Bit-Integers reichen.

Bitfelder unterstützen atomare Lese-, Schreib- und Inkrementierungsoperationen, was sie zu einer guten Wahl für die Verwaltung von Zählern und ähnlichen numerischen Werten macht. So können Bitfelder beispielsweise verwendet werden, um einfache Statistiken in einem Videospiel zu führen, wie etwa die Anzahl einer bestimmten Währung, wie Diamanten, oder die Anzahl der Tode.

Die Anzahl der Diamanten könnte beispielsweise am Offset 0 und die Anzahl der Tode am Offset 1 gespeichert werden. Die Breite dieser Zähler könnte auf 32 Bit festgelegt werden.

Der Befehl \emph{BITFIELD} in Redis ermöglicht das atomare Setzen, Inkrementieren und Lesen von Werten, während \emph{BITFIELD\_RO} als schreibgeschützte Variante dient, die speziell für leseintensive Anwendungen optimiert ist.


Die Leistung des Befehls \emph{BITFIELD} ist O(n), wobei n die Anzahl der zugegriffenen Zähler darstellt~\cite{redis_ltd_bitfields_nodate}.


\subsubsection{Geodatenindizes}
Der Datentyp \enquote{\emph{Geospatial}} ermöglicht die Speicherung und Abfrage von Koordinaten in Redis. So können z.~B. nahegelegene Punkte innerhalb eines bestimmten Radius oder eines definierten Begrenzungsrahmens ermittelt werden.
Ein praktisches Anwendungsbeispiel für diese Funktionalität wäre eine mobile Anwendung, die dem Benutzer die nächstgelegenen Elektroroller in seiner Umgebung anzeigt.

Zwei grundlegende Befehle sind in diesem Zusammenhang von zentraler Bedeutung: Der Befehl \emph{GEOADD} fügt einen Standort zu einem gegebenen georäumlichen Index hinzu, wobei zu beachten ist, dass bei diesem Befehl der Längengrad vor dem Breitengrad angegeben wird. Der Befehl \emph{GEOSEARCH} hingegen gibt Standorte innerhalb eines bestimmten Radius oder einer bestimmten Begrenzung zurück~\cite{redis_ltd_geospatial_nodate}.





\subsubsection{HyperLogLog}
\ac{HLL} ist eine probabilistische Datenstruktur in Redis, die Schätzung der Kardinalität einer Menge ermöglicht und dabei bis zu 12 KB Speicher verwendet. Diese Implementierung zeichnet sich durch einen Standardfehler von 0,81\% aus und kann Mengen mit bis zu \(2^{64}\) Mitgliedern schätzen.

Im Gegensatz zur traditionellen Zählung einzigartiger Elemente, die einen Spei\-cher\-platz proportional zur Element\-an\-zahl erfordert, bietet \ac{HLL} eine Spei\-cher\-platz-ef\-fi\-zi\-en\-te Schätzung mit einem geringen Fehleranteil.

Technisch gesehen unterscheidet sich \ac{HLL} von anderen Datenstrukturen in Redis, wird jedoch als Redis-String kodiert, wodurch \emph{GET} zur Serialisierung und \emph{SET} zur Deserialisierung eines \ac{HLL} genutzt werden kann.

Konzeptionell ähnelt die Nutzung von \ac{HLL} in einigen Aspekten dem Einsatz von Sets, insbesondere in der Verwaltung einzigartiger Elemente. Die direkte Speicherung der Elemente erfolgt jedoch nicht, stattdessen wird ein Zustand aufgezeichnet, der für Schätzungen verwendet wird.

Anwendungsbereiche von \ac{HLL} umfassen beispielsweise die Zählung einzigartiger Such\-anfragen oder die Bestimmung der Anzahl einzigartiger Besucher einer Webseite.

Bei den grundlegenden Befehlen für die Arbeit mit \ac{HLL} in Redis, erlaubt \emph{PFADD} das Eintragen eines Elements in ein \ac{HLL}. Die Anzahl der Elemente in einem \ac{HLL} lässt sich mit \emph{PFCOUNT} schätzen. Für das Zusammenführen von mehreren HyperLogLogs steht der Befehl \emph{PFMERGE} zur Verfügung.

Hinsichtlich der Leistungsfähigkeit zeichnen sich Schreib- (\emph{PFADD}) und Leseoperationen (\emph{PFCOUNT}) bei HyperLogLogs durch konstante Zeit- und Speicheranforderungen aus. Das Konsolidieren mehrerer HyperLogLogs mittels \emph{PFMERGE} stellt eine O(n)-Operation dar, wobei n die Anzahl der zu vereinenden HLLs repräsentiert.
~\cite{redis_ltd_hyperloglog_nodate}.


\subsubsection{Weitere Datentypen durch zusätzliche Module}
Durch Module können in Redis zusätzliche Datentypen wie zum Beispiel \emph{JSON} oder \emph{Time-Series}-Daten genutzt werden.

Das \emph{RedisJSON}-Modul bietet eine Unterstützung für JSON-Daten in Redis.
JSON-Daten können so direkt in der Redis-Datenbank gespeichert, aktualisiert und wieder abgerufen werden, was eine effiziente Verwaltung von komplexen Datenstrukturen ermöglicht. Hierzu zählen das gezielte Bearbeiten von Subelementen dank der \emph{JSONPath}-Syntax und ein schneller Zugriff auf Unterstrukturen von JSON-Dokumenten.
Außerdem ermöglicht RedisJSON atomare Operationen auf Datentypen innerhalb der JSON-Dokumente, um die Leistungsfähigkeit bei der Datenaufbereitung zu verbessern.
Ein wesentlicher Vorteil im Vergleich zur Speicherung von JSON als serialisierte Strings besteht in der Fähigkeit, JSON-Objekte zu indizieren und zu durchsuchen, was im Zusammenspiel mit dem \emph{RediSearch}-Modul ermöglicht wird.
Dadurch können komplexe Anfragen direkt in Redis ausgeführt werden~\cite{redis_ltd_json_nodate, redis_ltd_json-use-cases_nodate}.

Durch das \emph{RedisTimeSeries}-Modul können Zeitreihendaten in Redis gespeichert werden.
Dabei bietet Redis hohe Einfügeraten und schnelle Lesezugriffe.
Es ermöglicht Abfragen innerhalb spezifizierter Start- und Endzeiten sowie eine Vielfalt von aggregierten Abfragen, einschließlich, aber nicht beschränkt auf Minimum, Maximum, Durchschnitt und Summe, für beliebige Zeitintervalle.
Zudem lässt sich ein maximaler Aufbewahrungszeitraum konfigurieren und die Kompaktierung sorgt für automatisch aktualisierte, aggregierte Zeitreihen.
Durch die Verwendung von sekundären Indizes, welche auf Labels (Feld-Wert-Paare) basieren, können Zeitreiheneinträge gezielt abgefragt werden.
Die Daten können außerdem in anderen metrischen Programmen, wie beispielsweise Prometheus oder Grafana, weitergenutzt werden~\cite{redis_ltd_time_nodate}.


% Eventuell Abschnitt umstrukturieren

\subsection{Redis Cluster}
% https://learning.oreilly.com/library/view/mastering-redis/9781783988181/ch06.html#ch06lvl1sec42
% https://learning.oreilly.com/library/view/redis-4-x-cookbook/9781783988167/d590a8d8-2532-4601-9568-a52ccdcbec6f.xhtml

\section{RediSearch}

RediSearch ist ein Redis-Modul, das es ermöglicht, nach Daten in Redis über Indizes zu suchen.
Es unterstützt die Durchsuchung von HASH- und JSON-Werten, wobei letzteres das zusätzliche Modul \emph{RedisJSON} voraussetzt.
RediSearch verfügt über eine eigene Abfragesprache, die es auch ermöglicht, komplexere Suchanfragen und Aggregationen durchzuführen~\cite{redis_ltd_search_nodate}. %Wo Zitat hin?

RediSearch bietet verschiedene Such- und Abfragefunktionen.
So können Abfragen über mehrere Felder hinweg durchgeführt werden.
Zudem bietet es Aggregationsfunktionen und volltextbasierte Indexierung mehrerer Felder in einem Dokument.
Eine inkrementelle Indexierung ist ohne Leistungseinbußen möglich, sodass ein Index zuerst erstellt und danach eigenständig von Redis verwaltet sowie an sich ändernde Daten angepasst werden kann.

Weitere Funktionen umfassen logische Abfragen mithilfe von Operatoren wie \emph{AND}, \emph{OR} und \emph{NOT}, optionale Filterklauseln, präfixbasierte Suchen, Feldgewichtungen, Autovervollständigung und vage Präfix-Vorschläge (\enquote{Fuzzy-Prefix-Vorschläge}).
Es werden exakte Phrasensuchen und Distanzabhängige Suchen (\enquote{slop-basiert}) unterstützt. Darüber hinaus gibt es \emph{Stemming}-basierte Abfrageerweiterungen für viele Sprachen, einschließlich Deutsch und Englisch, mittels \emph{Snowball}.
RediSearch bietet eine begrenzte Unterstützung für benutzerdefinierte Funktionen zur Erweiterung und Bewertung von Suchanfragen (\enquote{Scoring}).

Zusätzlich dazu umfasst RediSearch numerische Filter und Bereichsabfragen, Geo-Filterung unter Verwendung von Redis-Geo-Befehlen und Suchfunktionen für Vektoren, die für semantische Suchaufgaben sowohl exakte als auch approximative Algorithmen verwenden.
Es unterstützt Unicode und ermöglicht das Abrufen von vollständigen Dokumentinhalten oder nur deren IDs.

RediSearch kann auch in verteilten Datenbank-Clustern eingesetzt werden.
\subsection{Interner Aufbau von RediSearch}
\subsubsection{Redis String DMA} % Ist das noch relevant?
\emph{Redis String DMA} ermöglicht es Redis-Modulen, Daten auf \enquote{Redis-String-Schlüssel} zu mappen. Sie erhalten dann direkte Zeiger auf die Daten, ohne diese kopieren oder serialisieren zu müssen.
Durch die Verwendung von \enquote{Redis String DMA} zum Kodieren von invertierten Indizes ermöglicht RediSearch einen schnellen Zugriff auf große Speichermengen~\cite{redis_ltd_internal_nodate}.


\subsubsection{Indizes in RediSearch}
Die derzeit verfügbare Dokumentation auf \emph{redis.io}~\cite{redis_ltd_internal_nodate} ist zum Zeitpunkt dieser Arbeit nicht mehr aktuell und bezieht sich auf Versionen vor der Einführung von RediSearch 2.0.
Mit der Einführung von Version 2.0 wurden erhebliche Änderungen vorgenommen, die von den in der Dokumentation beschriebenen Funktionalitäten wesentlich abweichen.
Diese Änderungen werden am Ende dieses Kapitels behandelt.
Es ist jedoch zu beachten, dass die nachfolgenden Informationen hauptsächlich auf der veralteten Dokumentation beruhen.

RediSearch implementiert invertierte Indizes innerhalb von Redis.
Es verwendet eine angepasste Datenkodierung (\enquote{\emph{Redis String DMA}}), die eine effiziente Speicher- und CPU-Suche ermöglicht.

Früher wurden solche Indizes als Sets direkt in Redis gespeichert, was speicherintensiv war und keine Kodierung von Offsets erlaubte. Seit Version 2.0 von RediSearch werden die Daten der Indizes separat gespeichert.

\subsubsection{Invertierte Indizes}
Der Invertierte Index in RediSearch enthält für jedes indizierte Wort bzw. Suchparameter eine Liste an Dokumenten, in denen es vorkommt.
Zusätzlich werden weitere Daten gespeichert, wie etwa die Häufigkeit und die Stellen, an denen der Suchbegriff im Dokument auftritt (\enquote{Offset}).
Bei einer Suche kann entweder ein einzelner Index oder eine Verbindung mehrerer Indizes nach dem Suchbegriff durchsucht werden.

Zusätzlich zu den invertieren Indizes werden weitere Daten in anderen \textit{Redis DMA string keys} gespeichert:\\
Der sogenannte \emph{Skip-Index}, eine Tabelle des Index-Offsets von einem Fünfzigstel der Einträge im Index. Dies ermöglicht eine schnellere Suche, wenn mehrere invertierte Indizes überschnitten werden, da nicht die gesamte Liste durchsucht werden muss.\\
Da bei der Suche nach einzelnen Wörtern nicht alle Treffer durchsucht werden, sondern nur die ersten N Treffer für den Benutzenden relevant sind, wird für jeden Suchbegriff ein Hilfsindex mit den ersten 20 oder mehr Einträgen erstellt, der sogenannte \emph{Score Index}.

Beim indizieren konnte früher angegeben werden, dass die Inhalte der Dokumente nicht gespeichert werden. Diese Option ist jedoch seit Version 2.0 von RediSearch nicht mehr verfügbar~\cite{redis_ltd_upgrade_nodate, korland_missing_nodate}.
% Hier eigentlich "Document and result ranking" aber veraltet ?!
% Sollte hier mehr ins Detail gegangen werden, was genau gespeichert wird?

\subsection{Nutzung von RediSearch} % Das müsste nen Überkapitel sein...

\subsection{Grundstrukturen in RediSearch}
Die Grundelemente von RediSearch sind in der Online-Dokumentation von Redis beschrieben~\cite{redis_ltd_basic_nodate}.
Sie bestehen aus \emph{Documents}, \emph{Fields} und dem \emph{Schema}.

\emph{Documents} sind die Basiseinheiten der Information, eindeutig identifizierbar durch ihren Schlüsselnamen, bestehend aus \emph{Hash}- oder \emph{JSON}-Datenobjekten. Jedes \emph{Document} enthält mehrere \emph{Fields}, die spezifische Attribute oder Eigenschaften repräsentieren und unterschiedliche Datentypen enthalten können. Bei einem Hash sind dies die einzelnen Elemente innerhalb des Hash und bei JSON die Felder des Dokuments.
Das \emph{Schema} definiert die Struktur des Index. Es legt fest, wie die \emph{Fields} gespeichert und indiziert werden.

Für eine effiziente Suche ist es wichtig, nur relevante \emph{Fields} zu indizieren, da die Indizierung aller \emph{Fields} zu unnötigem Overhead führen kann. Nicht indizierte \emph{Fields} tragen nicht zu den Suchergebnissen bei, können aber als Teil der \emph{Document}-Daten beim Abrufen der Suchergebnisse abgerufen werden. Aggregationen (siehe [VERWEIS AUF SPÄTERE KAPITEL]) können nur mit indizierten Feldern arbeiten. % TODO: Verweis auf Aggregation

\subsection{Anlegen von Inidizes}
Indizes werden in RediSearch mithilfe des Befehls \emph{FT.CREATE} erstellt.
Die Verwendung des Befehls wird in der Online-Dokumentation~\cite{redis_ltd_ftcreate_nodate} von Redis erläutert.
Die Syntax für die Erstellung lautet wie folgt:
\begin{lstlisting}[
    caption=Syntax des Befehls FT.CREATE in RediSearch,
    label=code:redisearch-ftcreate-syntax,
    numbers=none
]
FT.CREATE index 
  [ON HASH | JSON] 
  [PREFIX count prefix [prefix ...]] 
  [FILTER {filter}]
  [LANGUAGE default_lang] 
  [LANGUAGE_FIELD lang_attribute] 
  [SCORE default_score] 
  [SCORE_FIELD score_attribute] 
  [PAYLOAD_FIELD payload_attribute] 
  [MAXTEXTFIELDS] 
  [TEMPORARY seconds] 
  [NOOFFSETS] 
  [NOHL] 
  [NOFIELDS] 
  [NOFREQS] 
  [STOPWORDS count [stopword ...]] 
  [SKIPINITIALSCAN]
  SCHEMA field_name [AS alias] TEXT | TAG | NUMERIC | GEO | VECTOR | GEOSHAPE [ SORTABLE [UNF]] 
  [NOINDEX] [ field_name [AS alias] TEXT | TAG | NUMERIC | GEO | VECTOR | GEOSHAPE [ SORTABLE [UNF]] [NOINDEX] ...]
\end{lstlisting}

Die Erstellung eines Indexes in RedisSearch mittels des Befehls \emph{FT.CREATE} beinhaltet eine Reihe von Konfigurationsoptionen, die es ermöglichen, den Index an spezifische Anforderungen anzupassen.
Dabei sind nur die Argumente \emph{index} und \emph{SCHEMA} verpflichtend anzugeben. Alle anderen Argumente sind optional und werden im folgenden nur kurz erläutert.

Das Argument \emph{index} dient zur Angabe des Namens des zu erstellenden Indexes.

Innerhalb des \emph{SCHEMA}-Teils des Befehls werden die zu indizierenden Felder definiert. Der \emph{\{identifier\}} legt das Feld im Hash oder den JSON-Pfad-Ausdruck fest, während \emph{AS \{attribute\}} es erlaubt, einem Identifikator einen Aliasnamen zuzuweisen. Die verschiedenen Feldtypen und Optionen des Schemas werden in \ref{sec:redisearch-schema-fieldtypes} erläutert.


Das Argument \emph{ON \{data\_type\}} bestimmt die Datentypen, auf die der Index angewendet wird. Standardmäßig wird HASH verwendet, während JSON als alternative Option existiert.

Über \emph{PREFIX \{count\} \{prefix\}} werden die vom Index zu erfassenden Schlüssel bestimmt. Mehrere Präfixe können hinzugefügt werden, standardmäßig werden alle Schlüssel indiziert.

Der Ausdruck \emph{FILTER \{filter\}} erlaubt die Nutzung der RediSearch-Ag\-gre\-ga\-ti\-ons\-spra\-che für spezifische Filterungen.

Durch \emph{LANGUAGE \{default\_lang\}} und \emph{LANGUAGE\_FIELD \{lang\_attribute\}} werden die Standardsprache und das Sprachattribut des Dokuments festgelegt.

\emph{SCORE \{default\_score\}} und \emph{SCORE\_FIELD \{score\_attribute\}} definieren den Standardwert für die Dokumentenbewertung und das Attribut für die Benutzerrangfolge.

\emph{PAYLOAD\_FIELD \{payload\_attribute\}} ermöglicht es, ein Dokument mit einer binär sicheren Nutzlastzeichenfolge zu versehen.

Das Argument \emph{MAXTEXTFIELDS} zwingt RediSearch dazu, Indizes so zu kodieren, als ob sie mehr als 32 Textattribute enthalten, um die Flexibilität bei der Erweiterung zu erhöhen.

\emph{NOOFFSETS} verzichtet auf die Speicherung von Termoffsets, was Speicherplatz spart, aber gewisse Suchfunktionen einschränkt.

\emph{TEMPORARY \{seconds\}} erstellt einen temporären Index, der nach einer vorgegebenen Zeitspanne verfällt.

\emph{NOHL} deaktiviert die Hervorhebungsfunktion, um Speicherplatz zu sparen, während \emph{NOFIELDS} und \emph{NOFREQS} die Speicherung von Attributbits bzw. Häufigkeiten von Begriffen im Index unterbinden.

Mit \emph{STOPWORDS \{count\}} kann eine benutzerdefinierte Stoppwortliste festgelegt werden, und \emph{SKIPINITIALSCAN} vermeidet das sofortige Scannen und Indizieren von Dokumenten.




\subsection{Feldtypen und Optionen des Schemas}\label{sec:redisearch-schema-fieldtypes}
RediSearch bietet eine Auswahl an Feldtypen (\emph{field types}) für verschiedene Indexierungszwecke. Folgend werden die verschiedenen Feldtypen erläutert. Die Informationen stammen dabei, falls nicht anders angegeben, aus der Online-Dokumentation von Redis zu Feldtypen~\cite{redis_ltd_field_nodate} und dem \emph{FT.CREATE}-Befehl~\cite{redis_ltd_ftcreate_nodate}.

\subsubsection{\emph{Number fields}}
Nummernfelder speichern zählbare Werte in Ganzzahl- oder Gleitkommazahlen und erlauben sortierbare Bereichsabfragen. Sie können mit dem \emph{FT.CREATE}-Befehl wie folgt definiert werden:\\
\lstinline|FT.CREATE ... SCHEMA ... {field\_name} NUMBER [SORTABLE] [NOINDEX]|

Bedeutung der Optionen \emph{SORTABLE} und \emph{NOINDEX}:

- \emph{SORTABLE}: Ermöglicht die Sortierung des Feldes, nützlich für Bereichsabfragen und Sortierung von Suchergebnissen.

- \emph{NOINDEX}: Das Feld wird nicht indiziert, nützlich für Texte, die abrufbar, aber nicht durchsuchbar sein sollen.

Ein Beispiel für eine Query mit einem numerischen Filter könnte wie folgt sein:\\
\lstinline|FT.SEARCH recipeIndex "@cooking\_time:[10 30]"|

Queries unterstützen außerdem Syntax die angibt ob der Bereich vollständig einschließend, vollständig ausschließend , mit einer offenen Ober- oder Untergrenze sein soll. Zusätzlich kann auch explizit nach einem bestimmten Wert gesucht werden in dem die Grenzen des Bereichs die gleiche Zahl sind. Außerdem kann eine Filterbedingung auch negiert werden.

\subsubsection{\emph{Geo fields}} Diese Felder sind für geografische Koordinaten vorgesehen, die Radiusabfragen für standortbezogene Suchfunktionen ermöglichen.
Sie können mit dem \emph{FT.CREATE}-Befehl wie folgt definiert werden:\\
\lstinline|FT.CREATE ... SCHEMA ... \{field\_name\} GEO [SORTABLE] [NOINDEX]|

Die Optionen \emph{SORTABLE} und \emph{NOINDEX} entsprechen denselben Optionen wie bei \emph{numeric fields}. 

Der Syntax zur Abfrage von Geo-Feldern sieht wie folgt aus:\\
\lstinline|@<field\_name>:[<lon> <lat> <radius> <unit>]|

Um etwa Orte im Umkreis von 100 Kilometern um die Position von Furtwangen zu finden kann folgender Befehl genutzt werden:\\
\lstinline|FT.SEARCH cities "@coords:[8.20 48.05 100 km]"|

% TODO: Checken ob der Abschnitt so gut ist.
\subsubsection{\emph{Geoshape fields}}
Geosphape-Felder sind die neuesten Feldoptionen in RediSearch. Sie sind noch nicht in allen Dokumentationen vermerkt. Die Informationen beziehen sich auf die Dokumentation des \emph{FT.CREATE}-Befehls~\cite{redis_ltd_ftcreate_nodate} und die Dokumentation über Queries~\cite{redis_ltd_query_nodate}. 
Geoshapes ermöglichen geografische Abfragen mit der WKT-Notationen (\enquote{well-known text}).
Es werden sowohl Punkte wie auch Polygone unterstützt. Sie werden in einem Text wie folgt definiert:\\
\lstinline|POINT(2 4)| oder \lstinline|POLYGON((2 2, 2 8, 6 11, 10 8, 10 2, 2 2))|

Ein Eintrag kann dann beispielsweise so erstellt werden:\\
\lstinline|HSET shape:1 t "this is my house" g "POLYGON((2 2, 2 8, 6 11, 10 8, 10 2, 2 2))"|


Mit den Optionen \emph{FLAT} oder \emph{SPHERICAL} kann angegeben werden, ob die Koordinaten kartesisch  oder  geografisch sind.

Der Syntax für Queries zur Abfrage lautet wie folgt:\\
\lstinline+@field:[{WITHIN|CONTAINS} \$geometry] PARAMS 2 geometry \{geometry\}+

Ein Beispiel, in dem abgefragt wird, ob ein Polygon einen bestimmten Punkt beinhaltet könnte so aussehen:\\
\lstinline|FT.SEARCH polygon\_idx "@g:[CONTAINS \$point]" PARAMS 2 point 'POINT(8 8)' DIALECT 3|\\
\emph{DIALECT 3} gibt bei mehrwertigen Attributen statt Skalaren JSON zurück.
Komplexere Beispiele und Erklärungen sind in der Dokumentation zu Queries~\cite{redis_ltd_query_nodate} zu finden.


\subsubsection{\emph{Vector fields}} Vektor-Felder halten Gleitkommavektoren, die diverse unstrukturierte Daten wie etwa Text oder Bilder repräsentieren können, und unterstützen Vektorsimilaritätssuchen. Sie werden oft für externe Machine-Learning-Modelle genutzt.

Die Felder können mit dem \emph{FT.CREATE}-Befehl definiert werden:\\
\lstinline|FT.CREATE ... SCHEMA ... {field_name} VECTOR {algorithm} {count} |\\
\lstinline|[{attribute_name} {attribute_value} ...]|

Mit dem \emph{algorithm}-Attribut wird ein unterstützter Algorithmus für Vektorvergleiche angegeben. Er wird genutzt bei der Suche nach den k ähnlichsten Vektoren im Index oder beim Filtern von Vektoren nach Bereichen. Die unterstützten Algorithmen sind \emph{FLAT} für einen \enquote{brut force} Algorithmus und \emph{HNSM} für einen \enquote{hierarchical, navigable, small world} Algorithmus.

Das \emph{count}-Attribut gibt an, wie viele Attributpaare im Befehl verwendet werden. Wobei die Attributpaare die Algorithmusattribute für die Erstellung des Vektorindexes sind. Jeder Algorithmus hat seine eigenen obligatorischen und optionalen Attribute.

Ein Index kann zum Beispiel so erstellt werden:\\
\lstinline|FT.CREATE my_idx SCHEMA vec_field VECTOR FLAT 6 TYPE FLOAT32 DIM 128 | \\\lstinline|DISTANCE_METRIC L2|

Ein Beispiel für einen Vektorvergleich ist der \enquote{k nearest neighbors}(KNN)-Algorithmus. Die Syntax dazu ist wie folgt aufgebaut:\\
\lstinline+*=>[ KNN {num|\$num @vector \$query\_vec ]+\\
Eine Abfrage nach den zehn nächsten Nachbarn bei denen \enquote{query\_vec} am nächsten zum Vektor der in \enquote{@vector\_field} gespeichert ist sieht so aus:\\
\lstinline+*=>[KNN 10 @vector\_field \$query\_vec]+

Weitere Informationen und komplexere Beispiele sind in den Dokumentationen zu Queries~\cite{redis_ltd_query_nodate} und zu Vektoren~\cite{redis_ltd_vectors_nodate} zu finden.


\subsubsection{\emph{Tag fields}} In Tag-Feldern werden Textdaten als Tags oder Labels gespeichert, die ohne Tokenisierung verarbeitet werden. Sie eignen sich gut zur Datenorganisation und -kategorisierung.

Tags werden beim Erstellen des Index mit dem \emph{FT.CREATE}-Befehl wie folgt erstellt:\\
\lstinline|FT.CREATE ... SCHEMA ... {field\_name} TAG [SEPARATOR {sep}] [CASESENSITIVE]|

Der \emph{SEPARATOR} kann zur Angabe des Zeichens verwendet werden, das zum Trennen mehrerer Tags in einem Feld verwendet werden soll (Standard ist ein Komma).

\emph{CASESENSITIVE} gibt an, ob bei Tags die Groß- und Kleinschreibung zu beachten ist. Standardmäßig wird bei Tag-Feldern nicht zwischen Groß- und Kleinschreibung unterschieden (\enquote{\emph{caseinsensitive}}).

Um nach Tags zu suchen wird folgende Syntax verwendet:\\
\lstinline|@<field\_name>:\{<tag>\}|\\
Um etwa nach Rezepten mit Tomaten als Zutat zu suchen, kann folgender Befehl verwendet werden:\\
\lstinline|FT.SEARCH recipeIndex "@ingredients:\{tomato\}"|


\subsubsection{{\emph{Text fields}}}
Textfelder sind für die Speicherung menschlicher Sprache optimiert. Sie werden zu Kleinbuchstaben umgewandelt und tokenisiert, um effiziente Voll\-text\-su\-chen zu er\-mög\-li\-chen. Zu\-dem kön\-nen sie ge\-wich\-tet und sor\-tiert wer\-den, was ei\-ne dif\-fe\-ren\-zier\-te Such\-re\-le\-vanz und -ordnung ermöglicht.\\
Textfelder können mit dem FT.CREATE Befehl wie folgt angegeben werden:\\
% Hier vllt. nen fancigen codeblock aber ohne untertitel und so
\lstinline|FT.CREATE ... SCHEMA ... {field_name} TEXT [WEIGHT] [NOSTEM] [PHONETIC {matcher}]|\\ \lstinline|[SORTABLE] [NOINDEX] [WITHSUFFIXTRIE]|

Die Bedeutung der einzelnen Optionen:

- \emph{WEIGHT}: Gewichtet das Feld, um bestimmten Feldern bei der Suche mehr Bedeutung zu geben.

- \emph{NOSTEM}: Verhindert das Stemming des Feldes, nützlich für nicht zu tokenisierende Texte wie URLs.

- \emph{PHONETIC \{matcher\}}: Führt eine phonetische Übereinstimmung durch. Es können verschiedene \emph{matcher} für verschiedene Sprachen angegeben werden.

- \emph{WITHSUFFIXTRIE}: Indiziert das Feld mit einem Suffix-Trie, optimiert für Contains- und Suffix-Anfragen.

- Die Optionen \emph{SORTABLE} und \emph{NOINDEX} haben den gleichen Effekt wie bei \emph{Number fields}.

Die Suche nach Dokumenten mit bestimmten Textwerten ist möglich durch die Verwendung von \emph{<term>} oder \emph{@<field\_name>}:
\{<term>\} in der Abfragesyntax. Zum Beispiel:

% TODO: LatexProblem fixen, falsche Anführungszeichen (muss "" sein)
- Suche in allen Textattributen:
 \lstinline|FT.SEARCH recipeIndex \glqq egg\grqq|

- Suche nur im Preparation-attribut:
 \lstinline|FT.SEARCH recipeIndex "@preparation:boil"|




% TODO: Dieses Kapitel ergibt eventuell mehr Sinn vor dem vorherigen, da sich manche Beispiele auf diesen Index beziehen
\subsection{Anlegen eines Beispielindexes}
Das Indexschema legt die Felder, deren Typen sowie die Indizierungs- und Speicherregeln fest und ist entscheidend für die Effizienz der Suchfunktionalität sowie der Speichernutzung.
Die Definition des Schemas erfolgt bei der Indexerstellung mit dem Befehl \emph{FT.CREATE}~\cite{redis_ltd_ftcreate_nodate}.
Im Folgenden wird die Erstellung eines Index anhand eines Beispiels erläutert.
Der Index soll für das Rezeptverzeichnis eines Kochbuches verwendet werden.

\begin{lstlisting}[
    caption=Beispiel eines Befehls zum Anlegen eines Index in RediSearch,
    label=code:redisearch-creation-of-index-example
]
FT.CREATE recipeIndex
    ON HASH
    PREFIX 1 recipe:item:
SCHEMA
    name TEXT WEIGHT 5.0
    preparation TEXT
    ingredients TAG
    category TAG
    difficulty TAG
    cooking_time NUMERIC SORTABLE
\end{lstlisting}

Das Attribut\emph{ON HASH} gibt an, dass Hash-Dokumente indexiert werden sollen. Alternativ kann hier noch \emph{ON JSON} für JSON-Dokumente verwendet werden.
Der Prefix legt fest, dass nur Dokumente, die mit der angegebenen Zeichenfolge beginnen, indexiert werden. Zusätzlich zu diesen Attributen gibt es noch weitere optionale Attribute die in der Dokumentation des \emph{FT.CREATE}-Befehls erläutert werden, auf die hier jedoch nicht weiter eingegangen wird.
In diesem Fall initiiert der Befehl die Erstellung eines Index mit dem Namen \emph{recipeIndex}, der auf Hash-Dokumente mit dem Schlüsselanfang \emph{recipe:item:} angewendet wird. 
Das Schema dieses Index enthält die Felder \emph{name}, \emph{preparation}, \emph{ingredients}, \emph{category}, \emph{difficulty} und \emph{cooking\_time}.

Der Datentyp \emph{TEXT} wird für \emph{name} und \emph{preparation} verwendet, um die Textinformationen der Rezeptnamen und Zubereitungsanweisungen zu indizieren. Die Verwendung des Typs \emph{TAG} für \emph{ingredients} und \emph{category} erleichtert die Handhabung kategorisierter Daten wie Zutatenlisten und Rezeptkategorien. \emph{cooking\_time}, klassifiziert als \emph{NUMERIC} und \emph{SORTABLE}, ermöglicht die Suche und Sortierung nach Kochzeit. Das Feld \emph{difficulty} dient zur Angabe des Schwierigkeitsgrades des Rezeptes.

Dem Feld \emph{name} wird ein Gewicht von 5.0 zugewiesen, um seine Relevanz bei Suchanfragen zu erhöhen. Dieser Index ermöglicht eine effiziente Suche im Rezeptverzeichnis und das Filtern der Ergebnisse nach Kriterien wie Zutaten, Kategorie, Kochzeit und Schwierigkeitsgrad.

\subsection{Aggregations}
Aggregationen (Aggregations) stellen die effektivste Methode dar, um in Redis mit RediSearch Daten abzufragen. Die hier dargestellten Informationen basieren auf den Erklärungen, die in der Online-Dokumentation~\cite{redis_ltd_aggregations_nodate} von Redis zu finden sind.

Aggregationen ermöglichen die Verarbeitung und Analyse von Suchergebnissen durch verschiedene Operationen wie Gruppierung, Sortierung und Daten-Transformation. Ähnlich wie bei anderen Datenbanken sollen diese Verfahren dazu beitragen, analytische Erkenntnisse aus den Daten zu gewinnen. Des Weiteren können mit Aggregationen facettierte Suchanfragen durchgeführt werden. Suchergebnisse können so anhand verschiedener Merkmale oder \enquote{Facetten} gefiltert und verfeinert werden.

Ein Beispiel für den Einsatz einer Aggregation in RediSearch wäre eine OLAP-Abfrage, die berechnet wie oft Rezepte die Tomaten enthalten in den letzten drei Monaten aufgerufen wurden.

\subsubsection{Aufbau einer Aggregation}
Eine Aggregation-Query ist in zwei Teile unterteilt:\\
Zu Beginn wird eine Suche durchgeführt, bei der relevante Datensätze ausgewählt und gefiltert werden.
Anschließend wird eine Verarbeitungspipeline aufgebaut, bei der die Datensätze nach bestimmten Feldern gruppiert, sortiert, transformiert, limitiert und oder gefiltert werden. Die verschiedenen Schritte in einer Verarbeitungspipeline können beliebig oft ausgeführt werden und haben folgende Effekte:

- \emph{Group and reduce}: Gruppierung von Datensätzen nach bestimmten Feldern und Anwendung von Reduktionsfunktionen auf jede Gruppe, um aggregierte Daten zu erhalten.
    
- \emph{Sort}: Sortierung von Ergebnissen basierend auf einem oder mehreren Feldern.
    
- \emph{Apply transformations}: Anwenden von mathematischen Funktionen und Zeichenkettenfunktionen auf Felder in der Pipeline, wobei optional neue Felder erstellt oder bestehende Felder ersetzt werden können.
    
- \emph{Limit}: Begrenzung der Ergebnismenge, unabhängig von der Sortierreihenfolge, um eine handhabbare Datenmenge zu gewährleisten.
    
- \emph{Filter}: Nachträgliche Filterung der Ergebnisse auf der Grundlage von Prädikaten, die sich auf die Werte der Datensätze beziehen, um die Daten weiter zu verfeinern.

\subsubsection{Syntax einer Aggregation}\label{sec:redisearch-aggregation-syntax}
Aggregationen werden mit dem Befehl \emph{FT.AGGREGATE} ausgeführt der folgende Syntax hat:
\begin{lstlisting}[
    caption=Syntax des Befehls FT.AGGREGATE in RediSearch,
    label=code:redisearch-ftaggregate-syntax,
    numbers=none
]
FT.AGGREGATE
  {index_name:string}
  {query_string:string}
  [VERBATIM]
  [LOAD {nargs:integer} {property:string} ...]
  [GROUPBY
    {nargs:integer} {property:string} ...
    REDUCE
      {FUNC:string}
      {nargs:integer} {arg:string} ...
      [AS {name:string}]
    ...
  ] ...
  [SORTBY
    {nargs:integer} {string} ...
    [MAX {num:integer}] ...
  ] ...
  [APPLY
    {EXPR:string}
    AS {name:string}
  ] ...
  [FILTER {EXPR:string}] ...
  [LIMIT {offset:integer} {num:integer} ] ...
  [PARAMS {nargs} {name} {value} ... ]
\end{lstlisting}

Bei Parametern, die eine variable Anzahl an Argumenten haben, ist das erste Argument immer die Anzahl der Argumente {nargs:integer}. So werden Mehrdeutigkeiten beim Parsen zu vermieden, wenn eines der Argumente den gleichen Namen wie ein anderer Parameter hat.

Nachfolgend werden die einzelnen Argumente und ihre Parameter erläutert:

\emph{index\_name}: Der Name des zu verwendenden Index.

\emph{query\_string}: Die Basisabfrage. Sie folgt der Syntax der Suchabfrage, inklusive Filter und Operatoren.

\paragraph{\emph{LOAD \{nargs\} \{property\} ...}}: Lädt Dokumentfelder aus Hash-Objekten, beeinträchtigt jedoch die Leistung, Felder sollten wenn möglich als SORTABLE gespeichert werden. Es ist jedoch notwendig Felder zu laden, die nicht SORTABLE sind, um sie in weiteren Schritten der Pipeline zu nutzen. Außerdem werden nur geladene Felder am Ende der Abfrage ausgegeben.

\paragraph{\emph{GROUPBY \{nargs\} \{property\} ...}}: wird verwendet, um Ergebnisse nach einer oder mehreren Eigenschaften zu gruppieren. Diese Funktionalität ist ähnlich dem \emph{GROUP BY}-Statement in SQL. Die Ergebnisse werden dabei anhand eines oder mehrerer Felder gruppiert. Für jede Gruppe gibt Redis die Gruppenschlüssel oder die Werte, die allen Datensätzen in der Gruppe gemeinsam sind, sowie die Ergebnisse von null oder mehr \emph{REDUCE}-Klauseln zurück. Jeder \emph{GROUPBY}-Schritt in der Pipeline kann von null oder mehr \emph{REDUCE}-Klauseln begleitet werden (siehe nächsten Punkt).

\paragraph{\emph{REDUCE \{func\} \{nargs\} \{arg\} ... [AS \{name\}]}}: Reduziert Ergebnisse jeder Gruppe zu einem einzelnen Eintrag mittels einer Reduktionsfunktion wie etwa \emph{COUNT.} Optional kann das so entstandene Feld mit \enquote{AS \{name\}} benannt werden, andernfalls wird ein Name generiert der sich aus der Reduktionsfunktion und den Gruppeneigenschaften zusammensetzt.\\
Die mögliche Reducerfunktionen werden im folgenden kurz beschrieben:\\
\emph{COUNT}: Zählt die Anzahl der Einträge in jeder Gruppe.\\
\emph{COUNT\_DISTINCT}: Zählt die Anzahl unterschiedlicher Werte einer spezifischen Eigenschaft (eines Feldes) in der Gruppe.\\
\emph{COUNT\_DISTINCTISH}: Nutzt \emph{HyperLogLog} für eine annähernde Zählung mit einer Fehlerquote von 3\%, was Ressourcen bei großen Gruppen spart.\\
\emph{SUM}: Berechnet die Summe aller numerischen Werte einer bestimmten Eigenschaft in einer Gruppe. Nicht-numerische Werte werden als 0 gewertet.\\
\emph{MIN}: Liefert den minimalen Wert einer Eigenschaft in der Gruppe, unabhängig davon, ob es sich um einen String, eine Zahl oder NULL handelt.\\
\emph{MAX}: Gibt den maximalen Wert einer Eigenschaft in der Gruppe zurück, egal ob es sich um einen String, eine Zahl oder NULL handelt.\\
\emph{AVG}: Ermittelt den Durchschnittswert einer numerischen Eigenschaft in der Gruppe.\\
\emph{STDDEV}: Berechnet die Standardabweichung einer numerischen Eigenschaft innerhalb der Gruppe.\\
\emph{QUANTILE}: Gibt den numerischen Wert einer Eigenschaft zurück, die am angegebenen Quantil der Ergebnisse gemessen wird. Das Quantil wird als Zahl zwischen 0 und 1 angegeben, wobei der Median beispielsweise das Quantil 0,5 darstellt.\\
\emph{TOLIST}: Kombiniert alle unterschiedlichen Werte einer Eigenschaft in einem Array.\\
\emph{FIRST\_VALUE}: Gibt den ersten oder obersten Wert einer Eigenschaft in der Gruppe zurück, optional durch Vergleich mit einer anderen Eigenschaft.\\
\emph{RANDOM\_SAMPLE}: Führt eine Reservoir-Stichprobenziehung von Elementen in der Gruppe mit festgelegter Größe durch und gibt ein Array der Stichproben mit gleichmäßiger Verteilung zurück.


\paragraph{\emph{SORTBY \{nargs\} \{property\} \{ASC|DESC\} [MAX \{num\}]}}: Sortiert Ergebnisse nach Eigenschaften. Standardmäßig aufsteigend, umkehrbar mit ASC oder DESC. Mit dem Attribut \emph{MAX} kann die Sortierung optimiert werden in dem sie nur die n-größten Elemente sortiert.

\paragraph{\emph{APPLY {expr} AS {name}}}: Führt eine Transformation auf Eigenschaften aus. \emph{expr} beinhaltet Berechnungen oder Funktionen auf numerischen oder anderen Eigenschaftstypen. Aus Gründen der Relevanz wird auf die verschiedenen unterstützten Funktionen hier nicht detaillierter eingegangen. Eine ausführliche Beschreibung findet sich in der Dokumentation von Redis~\cite{redis_ltd_aggregations_nodate}. Das Ergebnis des Transformation wird als neue Eigenschaft mit \emph{AS {name}} gespeichert und ist in nachfolgenden Operationen verwendbar.

\paragraph{\emph{LIMIT \{offset\} \{num\}}}: Begrenzt die Anzahl der Ergebnisse die zurückgegeben werden. Dabei wird die Anzahl der Ergebnisse festgelegt und ab welchem Offset sie ausgewählt werden sollen. Falls die Ergebnisse auch sortiert werden ist es effizienter, sie mit dem Attribut \emph{MAX} des Befehls \emph{SORTBY} zu limitieren.

\paragraph{\emph{FILTER \{expr\}}}: Filtert Ergebnisse mit Prädikatausdrücken.\\
Die \emph{FILTER}-Ausdrücke werden nach der Abfrage ausgewertet und beziehen sich auf den aktuellen Zustand der Pipeline. Sie sind nützlich, um Ergebnisse auf Basis von Gruppenberechnungen zu filtern. Filterausdrücke folgen der Syntax von \emph{APPLY}-Ausdrücken, ergänzt durch die Bedingungen \lstinline|==, !=, <, <=, >, >=|.

\paragraph{\emph{PARAMS \{nargs\} \{name\} \{value\}}}: Definiert Parameter für die Abfrage die aus einem Namen und einem Wert bestehen. Parameter können in der Abfrage durch \$-Zeichen und dem Namen referenziert werden. Jede Referenz in der Suchanfrage auf einen Parameternamen wird dann durch den entsprechenden Parameterwert ersetzt.

\subsubsection{Aggregationsbeispiele}
Im Folgenden werden unterschiedliche Beispiele für Aggregationsabfragen präsentiert und erklärt.

Dabei wird von einem Datensatz von Rezepten in Form von HASH-Dokumenten ausgegangen (siehe \cref{pic:redisearch-aggregation-example-entry}).

% Dafür sorgen dass Abbildung an richtiger Stelle im Text ist!
\begin{figure}[hp]  % figure position
    \centering      % center the image
    \includegraphics[width=1\textwidth]{pictures/redis/redisearch_aggregation_example_entry.png}
    \caption{Beispieleintrag in der Rezeptdatenbank}      % caption the image
    \label{pic:redisearch-aggregation-example-entry}    % label the image for internal referencing
\end{figure}

Der Beispielindex~\ref{code:redisearch-creation-of-index-example} aus den vorherigen Abschnitten  wird als Index genutzt.


Die Beispiele werden anhand von Screenshots aus der CLI in RedisInsight dargestellt. Dabei entspricht die erste Zeile jeweils der Aggregationsabfrage, die folgenden Zeilen stellen die Ergebnisse dar.



\paragraph{Die drei Rezepte mit den längsten Kochzeiten}
\cref{pic:redisearch-aggregation-example-1} Zeigt ein Aggregationsbeispiel das die drei Rezepte mit den längsten Kochzeiten findet.\\
% Dafür sorgen dass Abbildung an richtiger Stelle im Text ist!
\begin{figure}[ht]  % figure position
    \centering      % center the image
    \includegraphics[width=1\textwidth]{pictures/redis/redisearch_aggregation_example_1.png}
    \caption{Aggregationsbeispiel 1: Top 3 Rezete mit längster Kochdauer}      % caption the image
    \label{pic:redisearch-aggregation-example-1}    % label the image for internal referencing
\end{figure}

RediSearch sucht zunächst mit \lstinline|*| nach allen Dokumenten.\\
Anschließend werden die die beiden Felder \lstinline|@name @cooking\_time| mit \lstinline|LOAD 2 @name @cooking\_time|  geladen. Für die restliche Pipeline ist dies nicht zwingend notwendig, da \lstinline|SORTBY| auch bei nicht geladenen Feldern funktioniert, solange diese \emph{sortable} sind (siehe \ref{sec:redisearch-aggregation-syntax}). Jedoch würden ohne diese Anweisung die Namen der Rezepte nicht im Ergebnis der Abfrage zurückgegeben werden.\\
Als letzter Schritt werden die Ergebnisse anhand der Kochzeit sortiert: \lstinline|SORTBY 2 @cooking\_time DESC MAX 3|. \lstinline|DESC| gibt hierbei an, dass die Ergebnisse absteigend sortiert werden. Die Anweisung \lstinline|MAX 3| sorgt dafür, dass nur die ersten drei Dokumente zurückgegeben werden.


% Schauen, ob zuerst Text oder Bild kommen soll
\paragraph{Anzahl der Rezepte pro Schwierigkeitsgrad}
Die in \cref{pic:redisearch-aggregation-example-2} dargestellte Abfrage ermittelt, wie viele Rezepte es pro Schwierigkeitsgrad gibt.

% Dafür sorgen dass Abbildung an richtiger Stelle im Text ist!
\begin{figure}[ht]  % figure position
    \centering      % center the image
    \includegraphics[width=1\textwidth]{pictures/redis/redisearch_aggregation_example_2.png}
    \caption{Aggregationsbeispiel 1: Anzahl der Rezepte pro Schwierigkeitsgrad}      % caption the image
    \label{pic:redisearch-aggregation-example-2}    % label the image for internal referencing
\end{figure}

Als erster Schritt wird mit (\lstinline|*|) nach allen Dokumenten im Index gesucht.\\
Anschließend werden mit \lstinline|GROUPBY 1 @difficulty| alle Dokumente anhand der Schwierigkeit gruppiert.\\ 
Außerdem wird mit \lstinline|COUNT 0 AS num\_recipes| ein neues Feld namens \enquote{\emph{num\_recipes}} hinzugefügt, das angibt, wie viele Rezepte in jeder Schwierigkeitskategorie vorhanden sind.



\paragraph{Durchschnittliche Kochzeit nach Kategorie}
\cref{pic:redisearch-aggregation-example-3} zeigt eine Abfrage, die die durchschnittliche Kochzeit pro Kategorie ermittelt.

% Dafür sorgen dass Abbildung an richtiger Stelle im Text ist!
\begin{figure}[ht]  % figure position
    \centering      % center the image
    \includegraphics[width=1\textwidth]{pictures/redis/redisearch_aggregation_example_3.png}
    \caption{Aggregationsbeispiel 2: Durchschnittliche Kochzeit nach Kategorie (Ausschnitt)}      % caption the image
    \label{pic:redisearch-aggregation-example-3}    % label the image for internal referencing
\end{figure}

Zu Beginn wird nach allen Dokumenten gesucht.\\
Anschließend werden die Dokumente nach Schwierigkeitsgrad gruppiert und ein neues Feld \lstinline|avg\_cooking\_time| eingefügt, das die berechnete durchschnittliche Kochzeit der Rezepte nach Kategorie beinhaltet.\\
Anschließend werden die Kategorien mit \lstinline|SORTBY 2 @avg\_cooking\_time ASC| nach durchschnittlicher Kochzeit sortiert.
\lstinline|ASC| steht hierbei für \enquote{ascending} (aufsteigend). Da es sich  bei der Kochzeit um ein Feld handelt, muss ein \enquote{@} vorangestellt werden. In der \emph{REDUCE}-Anweisung weiter vorne wird der Name des zu erstellenden Felde ohne \enquote{@} angegeben.





















\section{Scala} % Todo: Eventuell ausbauen
Scala ist eine moderne Programmiersprache die Merkmale objektorientierter und funktionaler Sprachen aufweist.
Sie zeichnet sich außerdem durch eine starke Typisierung aus.
Ihre Syntax zeigt Parallelen zu Java auf, und es ist möglich, Java-Funktionen sowie Java-Libraries in Scala zu verwenden~\cite{epfl_scala_nodate-1, epfl_introduction_nodate}.
Scala läuft in der JVM, mit JavaScript im Browser oder nativ mit LLVM~\cite{epfl_scala_nodate}.

\subsection{Einsatzgebiete von Scala}
Auf dem \emph{\acf{PYPL}} belegt Scala im November 2023 den 20. Platz der beliebtesten Programmiersprachen~\cite{carbonnelle_pypl_2023}.
Durch die Kompatibilität mit Java eigenet sich Scala auch für alle gängigen Einsatzgebiete von Java. 
Durch Scalas besondere Eigenschaften eignet es sich jedoch besonders für hochdurchsatzfähige HTTP-Server und -Clients, in Form von Skripten für die Kommandozeile, mit JavaScript im Frontend-Web sowie für die Datenverarbeitung.

Scala wird außerdem häufig mit \emph{Akka}~\cite{lightbend_akka_nodate} für verteilte Anwendungen verwendet.

\subsection{Vorteile von Scala}
Scala hat einige Charakteristiken, die ihm im Vergleich zu Java einen Vorteil verschaffen.
Besonders zu betonen sind folgende Eigenschaften von Scala im Gegensatz zu Java~\cite{epfl_scala_nodate-1, epfl_scala_nodate-2}: % Quellenangabe hier so okay?

\begin{enumerate}
    \item \emph{Kompakterer und ausdrucksstärkerer Code:} Scala ermöglicht oftmals kürzere und prägnantere Codezeilen im Vergleich zu Java. Dies wird durch spezifische Konstrukte in Scala, wie \emph{case}-Klassen und Collections-Operationen (\emph{map} und \texttt{toMap}), sowie durch Pattern Matching erreicht, was den Code weniger umfangreich und einfacher lesbar macht.
    
    \item \emph{Funktionale Programmierung:} Scala, eine Sprache, die objektorientierte und funktionale Programmierstile unterstützt, bietet Vorteile durch funktionale Konzepte wie Higher-Order-Funktionen und effiziente Methoden zur Transformation von Collections. Diese Eigenschaften sind in Java oft weniger elegant umsetzbar oder erfordern mehr Boilerplate-Code.
    
    \item \emph{Immutability und Case Classes:} Der Einsatz von Unveränderlichkeit (Immutability) bei der Definition von Datenstrukturen ist in Scala weniger komplex als in Java. Scala's \emph{case}-Klassen unterstützen Unveränderlichkeit und Pattern Matching, was die Sicherheit und Wartbarkeit des Codes erhöht.
    
    \item \emph{Pattern Matching:} Scalas Implementierung von Pattern Matching ermöglicht eine elegantere und sicherere Handhabung potenziell fehlender Werte, ein Ansatz, der in Java nicht so nativ und leserlich umgesetzt ist.
    
    \item \emph{Typinferenz:} Durch Scala's Typinferenz wird der Bedarf an expliziten Typdeklarationen reduziert, was den Code weniger überladen und besser lesbar macht – ein Aspekt, der in Java oft durch die Notwendigkeit expliziter Typangaben nicht gegeben ist.
\end{enumerate}


\subsection{Redis mit Scala (Jedis)} %subsection oder subsubsection?
Jedis ist ein Java-Client für Redis, der sich durch hohe Leistung und einfache Benutzbarkeit auszeichnet. Als Hauptvorteile bietet Jedis fortgeschrittene Unterstützung für verschiedene Redis-Versionen, eine effiziente Handhabung potenziell fehlender Werte durch Pattern Matching sowie eine Unterstützung für Redis-Module wie RediSearch~\cite{redis_inc_jedis_2023}.
Da Scala mit Java-Bibliotheken kompatibel ist lässt sich Jedis mit wenig Mehraufwand auch in Scala nutzen. % -> Hier Verweis auf Implementierungskapitel wo kurz erklärt wird dass man die scla-java-converter nutzen muss.

Grundsätzlich gibt es Bibliotheken für die Arbeit mit Redis in vielen Programmiersprachen und der Quellcode, der während dieser Arbeit erstellt wurde, wäre auch in anderen modernen Programmiersprachen wie etwa Java oder Python möglich gewesen.
Die Entscheidung für Scala in dieser Arbeit basiert auf den oben genannten Vorteilen und der persönlichen Präferenz des Autors.


\section{Lua}
Lua ist eine Programmiersprache, die auf ihrer offiziellen Webseite als mächtige, effiziente, leichtgewichtige und integrierbare Skriptsprache beschrieben wird~\cite{ierusalimschy_lua_nodate}. Die Sprache unterstützt eine Vielzahl von Programmierparadigmen wie prozedurale Programmierung, objektorientierte Programmierung, funktionale Programmierung, datengesteuerte Programmierung und Datenbeschreibung. Die Informationen in den folgenden Abschnitten stammen, sofern nicht anders angegeben, von der offiziellen Lua-Webseite.

\subsection{Einsatzgebiete von Lua}
Auf dem \emph{\acf{PYPL}} belegt Lua im November 2023 den 21. Platz der beliebtesten Programmiersprachen~\cite{carbonnelle_pypl_2023}.

Aufgrund ihrer geringen Größe wird Lua häufig als Skriptsprache innerhalb von Anwendungen verwendet. Ein Beispiel hierfür ist \emph{Fusion 18}~\cite{blackmagic_design_fusion_nodate}, eine in Hollywood häufig verwendete Compositing-Software. Auch in der Videospielbranche wird Lua häufig für Erweiterungen verwendet, z.~B. bei \emph{World of Warcraft}~\cite{wowpedia_lua_2023}.

Lua-Skripte können auch innerhalb von \emph{Redis} ausgeführt werden~\cite{redis_ltd_scripting_nodate}. Die Skripte laufen direkt auf dem Redis-Server, was die Interaktion mit Redis sehr effizient macht.
Lua ist kompatibel mit allen Unix- und Windows-Systemen, läuft auf eingebetteten Mikroprozessoren sowie auf Smartphones mit iOS und Android.

Die Programmiersprache verfügt über eine einfache und gut dokumentierte API, die eine enge Integration mit in anderen Sprachen geschriebenem Code ermöglicht. Es ist einfach, Lua mit Bibliotheken zu erweitern, die in anderen Sprachen geschrieben wurden. Ebenso ist es einfach, Programme, die in anderen Sprachen geschrieben wurden, mit Lua zu erweitern.
\subsection{Technische Aspekte}
Die technischen Aspekte werden im \emph{Reference Manual}~\cite{ierusalimschy_lua_nodate-1} erklärt.

Lua wurde als Bibliothek in \emph{clean C} implementiert. Es ist eine dynamisch typisierte Programmiersprache, die Bytecode durch Interpretation mit einer registrierbasierten virtuellen Maschine verarbeitet.

Lua umfasst nur acht grundlegende Datentypen: \emph{nil}, \emph{boolean}, \emph{number}, \emph{string}, \emph{function}, \emph{userdata}, \emph{thread} und \emph{table}.

Der Datentyp \emph{nil} hat ausschließlich den Zweck, sich von allen anderen Datentypen zu unterscheiden und ähnelt dem Datentyp \emph{null} in Java. Der Datentyp \emph{number} repräsentiert sowohl ganze Zahlen als auch reelle Zahlen und wird in die Untertypen \emph{integer} und \emph{float} unterteilt.

Der Datentyp \emph{string} stellt unveränderliche Bytefolgen dar und kann jeden 8-Bit-Wert enthalten. Der Datentyp \emph{thread} steht zur Implementierung von \emph{Coroutinen} unabhängiger Ausführungsstränge bereit und steht nicht im Zusammenhang mit Betriebssystem-Threads.
Lua-Funktionen sowie C-Funktionen werden mit dem Datentyp \emph{function} dargestellt.
Der Datentyp \emph{userdata} dient dazu, C-Daten in Lua-Variablen zu speichern.

In dieser Arbeit findet der Datentyp \emph{table} besondere Beachtung, der assoziative Arrays implementiert, die nicht nur Zahlen, sondern auch beliebige Lua-Werte außer \emph{nil} und \emph{NaN} (ein spezieller Wert nach dem IEEE 754 Standard der undefinierte numerische Ergebnisse wie etwa \enquote{0/0} darstellt) als Indizes haben können.
Tabellen sind in Lua der einzige Mechanismus zur Strukturierung von Daten. Sie können verwendet werden, um gewöhnliche Arrays, Listen, Symboltabellen, Sets, Records, Graphen, Bäume und andere Datentypen darzustellen.

\subsection{Lua in Redis}
Redis ermöglicht das direkte Ausführen von Lua-Skripten auf dem Server, wodurch die Redis-Befehle der Skripte effizient verarbeitet werden können, da diese nicht über das Netzwerk übertragen werden müssen. Diese Skripte garantieren eine atomare Ausführung, bei welcher sämtliche Serveraktivitäten während der Laufzeit des Skripts blockiert sind. Die Möglichkeiten von Lua-Skripten in Redis werden in der Online-Dokumentation von Redis erläutert~\cite{redis_ltd_scripting_nodate}.

Durch die Möglichkeit eigene Funktionen für komplexe Aufrufe zu erstellen, wird Redis mittels Skripten leicht erweiterbar. Die meisten \emph{Redis-Befehle} können in \emph{Lua-Skripten} genutzt werden.

Unterschieden werden muss bei der Verwendung von Lua-Skripten in Redis zwischen klassischen Skripten, die mit dem \emph{EVAL}-Befehl ausgeführt werden, und den sogenannten \emph{Redis Functions}~\cite{redis_ltd_redis_nodate-1}. Klassische Skripte erfordern bei jedem Aufruf durch den \emph{EVAL}-Befehl das Senden des Skripts an den Redis-Server, was zu einem Netzwerk- und Kompilierungs-Overhead führt, wenn Skripte mehrfach verwendet werden sollen.

Im Gegensatz dazu bieten \emph{Redis Functions} dieselbe Funktionalität wie klassische Skripte, aber mit dem Vorteil, dass Redis sie als Teil der Datenbank verwaltet und für ihre Verfügbarkeit sorgt.  So werden \emph{Functions} auch auf der Festplatte persistiert. Sie müssen nur einmalig an den Redis-Server gesendet werden und können dann beliebig oft aufgerufen werden. Die \emph{Functions} werden als so genannte \emph{Library} verwaltet, wobei eine Library mehrere \emph{Functions} enthalten kann, die sich somit auch Code teilen können.

In der Online-Dokumentation von Redis wird auch die Redis-Lua-API~\cite{redis_ltd_redis_nodate} sowie das Debuggen von Lua-Skripten~\cite{redis_ltd_debugging_nodate} erläutert.

